{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a68f59d3",
   "metadata": {
    "papermill": {
     "duration": 0.007085,
     "end_time": "2024-11-07T19:03:17.067435",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.060350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Google - Unlock Global Comm with Gemma\n",
    "\n",
    "Upadted on: 08/11/2024\n",
    "\n",
    "Author: Mohammad Rifat Ahmmad Rashid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdf2118",
   "metadata": {
    "papermill": {
     "duration": 0.00609,
     "end_time": "2024-11-07T19:03:17.080003",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.073913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine-tuning Gemma 2 for Bangla Language tasks\n",
    "\n",
    "\n",
    "Bangla is a widely spoken language in Bangladesh and parts of India. Approximately 230 million people speak Bangla as their first language. In this notebook, we fine-tune Gemma 2 for conversational Bangla to provide a resource for cancer patients seeking consultations in Bangla about their health-related queries\n",
    "\n",
    "This is a notebook for \"Google- Unlock Glbal Communication with Gemma\" Competition :\n",
    "``https://www.kaggle.com/competitions/gemma-language-tuning``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a5635",
   "metadata": {
    "papermill": {
     "duration": 0.006065,
     "end_time": "2024-11-07T19:03:17.092377",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.086312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "This notebook is focused on fine-tuning the Gemma 2 model for handling conversational tasks in Bangla, a language predominantly spoken in Bangladesh and parts of India. The notebook is specifically designed to assist patients in getting their queries about cancer addressed in Bangla.\n",
    "\n",
    "The initial cells introduce the competition on Kaggle where Gemma 2 is used for language tuning. The notebook provides resources for setting up the Gemma 2 model and references to other tutorials and datasets, such as the Bangla-Instruct dataset from Hugging Face. Additionally, users are advised to use a GPU (specifically, the P100 model) to manage the model's VRAM requirements during fine-tuning.\n",
    "\n",
    "Several cells demonstrate how to fine-tune the model for generating Bangla responses in different scenarios. These include generating responses to patient queries, such as different treatments in Bangla for various cancer inquiries. Sample responses are crafted using pre-defined prompts in Bangla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c05b11f",
   "metadata": {
    "papermill": {
     "duration": 0.006148,
     "end_time": "2024-11-07T19:03:17.105740",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.099592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reference Notebooks\n",
    "1. https://www.kaggle.com/code/bebechien/how-to-finetuning-gemma2-for-spoken-language-tasks\n",
    "2. https://www.kaggle.com/code/mpwolke/bhagavad-gita-gemma2keras\n",
    "3. https://www.kaggle.com/code/crsuthikshnkumar/google-gemma-unlock-hindi-cancer-qa-nb-crsk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285fcf1f",
   "metadata": {
    "papermill": {
     "duration": 0.006091,
     "end_time": "2024-11-07T19:03:17.118214",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.112123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Google  Gemma Models:\n",
    "\n",
    "1. Google Gemma https://ai.google.dev/gemma\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a4983a",
   "metadata": {
    "papermill": {
     "duration": 0.006008,
     "end_time": "2024-11-07T19:03:17.130449",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.124441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Video Tutorials\n",
    "1. Tune Gemma as a Spoken Language AI Assistant | Build with Google AI https://youtu.be/M4HGJehH4r0?si=5tk9cIdALXQ1xdmU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf38c96",
   "metadata": {
    "papermill": {
     "duration": 0.005957,
     "end_time": "2024-11-07T19:03:17.142606",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.136649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DataSets\n",
    "Main focus of the dataset is for visual question answering (VQA) task, likely focusing on cultural or historical sites in bangladesh, given the content of the questions and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4975fbe6",
   "metadata": {
    "papermill": {
     "duration": 0.006131,
     "end_time": "2024-11-07T19:03:17.154873",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.148742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Using accelerators\n",
    "\n",
    "Please use **GPU P100** due to VRAM requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44df1fe3",
   "metadata": {
    "papermill": {
     "duration": 0.006421,
     "end_time": "2024-11-07T19:03:17.167459",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.161038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Details of this notebook\n",
    "\n",
    "### Gemma setup\n",
    "\n",
    "setup instructions at [Gemma setup](https://ai.google.dev/gemma/docs/setup). \n",
    "\n",
    "Gemma models are hosted by Kaggle. To use Gemma,  access on Kaggle is required:\n",
    "\n",
    "- Sign in or register at [kaggle.com](https://www.kaggle.com)\n",
    "- Open the [Gemma 2 model card](https://www.kaggle.com/models/google/gemma-2) and select _\"Request Access\"_\n",
    "- Complete the consent form and accept the terms and conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d63684",
   "metadata": {
    "papermill": {
     "duration": 0.006017,
     "end_time": "2024-11-07T19:03:17.180066",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.174049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install dependencies\n",
    "\n",
    "Install Keras and KerasNLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c36dc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T19:03:17.194813Z",
     "iopub.status.busy": "2024-11-07T19:03:17.194408Z",
     "iopub.status.idle": "2024-11-07T19:03:58.750356Z",
     "shell.execute_reply": "2024-11-07T19:03:58.749507Z"
    },
    "papermill": {
     "duration": 41.566446,
     "end_time": "2024-11-07T19:03:58.752681",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.186235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n",
    "!pip install -q -U keras-nlp datasets\n",
    "!pip install -q -U keras\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Set the backbend before importing Keras\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "# Avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\"\n",
    "\n",
    "import keras_nlp\n",
    "import keras\n",
    "\n",
    "# Run at half precision.\n",
    "#keras.config.set_floatx(\"bfloat16\")\n",
    "\n",
    "# Training Configurations\n",
    "token_limit = 256\n",
    "num_data_limit = 100\n",
    "lora_name = \"cakeboss\"\n",
    "lora_rank = 4\n",
    "lr_value = 1e-4\n",
    "train_epoch = 20\n",
    "model_id = \"gemma2_instruct_2b_en\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64ad6a7",
   "metadata": {
    "papermill": {
     "duration": 0.006008,
     "end_time": "2024-11-07T19:03:58.765355",
     "exception": false,
     "start_time": "2024-11-07T19:03:58.759347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed2f869",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T19:03:58.779316Z",
     "iopub.status.busy": "2024-11-07T19:03:58.778761Z",
     "iopub.status.idle": "2024-11-07T19:05:03.535104Z",
     "shell.execute_reply": "2024-11-07T19:05:03.533839Z"
    },
    "papermill": {
     "duration": 64.765879,
     "end_time": "2024-11-07T19:05:03.537403",
     "exception": false,
     "start_time": "2024-11-07T19:03:58.771524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,614,341,888\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "Do you know bangla language?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "As an AI, I don't \"know\" languages in the way a human does. I can't speak or understand Bengali in the same way you do. \n",
      "\n",
      "However, I have been trained on a massive dataset of text and code, which includes a significant amount of Bengali content. This means I can:\n",
      "\n",
      "* **Translate** Bengali to other languages and vice versa.\n",
      "* **Generate** text in Bengali, like writing simple sentences or stories.\n",
      "* **Identify** Bengali text and understand its meaning.\n",
      "* **Answer** questions about Bengali grammar and vocabulary.\n",
      "\n",
      "So, while I don't \"know\" Bengali in the human sense, I can still be helpful with tasks related to the language. \n",
      "\n",
      "How can I help you with Bengali today? 😊 \n",
      "<end_of_turn>\n",
      "TOTAL TIME ELAPSED: 19.80s\n",
      "\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "আপনি কি বাংলা জানেন?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "আমি বাংলা ভাষা জানি।  আমি এখনও শিক্ষা করছি, কিন্তু আমি বেশিরভাগ সময় বাংলাতে কথা বলতে পারি। \n",
      "\n",
      "আপনি কি কিছু বাংলাতে বলতে চান? \n",
      "<end_of_turn>\n",
      "TOTAL TIME ELAPSED: 2.49s\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "\n",
    "import time\n",
    "\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(model_id)\n",
    "gemma_lm.summary()\n",
    "\n",
    "tick_start = 0\n",
    "\n",
    "def tick():\n",
    "    global tick_start\n",
    "    tick_start = time.time()\n",
    "\n",
    "def tock():\n",
    "    print(f\"TOTAL TIME ELAPSED: {time.time() - tick_start:.2f}s\")\n",
    "\n",
    "def text_gen(prompt):\n",
    "    tick()\n",
    "    input = f\"<start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "    output = gemma_lm.generate(input, max_length=token_limit)\n",
    "    print(\"\\nGemma output:\")\n",
    "    print(output)\n",
    "    tock()\n",
    "\n",
    "# inference before fine-tuning\n",
    "text_gen(\"Do you know bangla language?\")\n",
    "text_gen(\"আপনি কি বাংলা জানেন?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6bac1c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T19:05:03.555242Z",
     "iopub.status.busy": "2024-11-07T19:05:03.554902Z",
     "iopub.status.idle": "2024-11-07T19:05:04.192052Z",
     "shell.execute_reply": "2024-11-07T19:05:04.190849Z"
    },
    "papermill": {
     "duration": 0.648455,
     "end_time": "2024-11-07T19:05:04.194107",
     "exception": false,
     "start_time": "2024-11-07T19:05:03.545652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Translated Questions</th>\n",
       "      <th>Translated Answers</th>\n",
       "      <th>Title(region name)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>এই ছবিটি কিসের?</td>\n",
       "      <td>এই ছবিটি হলো পুঠিয়া রাজবাড়ী বা পাঁচআনি জমিদ...</td>\n",
       "      <td>What is this picture of?</td>\n",
       "      <td>This picture is of the Puthia Rajbari or Panch...</td>\n",
       "      <td>পুঠিয়া রাজবাড়ী, নাটোর, রাজশাহী।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>এটি কোন দিক রাজবাড়ীর?</td>\n",
       "      <td>এটি রাজবাড়ীর সম্মুখভাগ</td>\n",
       "      <td>Which direction of the palace is this?</td>\n",
       "      <td>This is the front section of the palace.</td>\n",
       "      <td>পুঠিয়া রাজবাড়ী, নাটোর, রাজশাহী।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>পুঠিয়া রাজবাড়ী কয় তলা বিশিষ্ট?</td>\n",
       "      <td>পুঠিয়া রাজবাড়ী দ্বিতল বিশিষ্ট এবং  ইন্দো ইউর...</td>\n",
       "      <td>How many stories does the Puthia Rajbari have?</td>\n",
       "      <td>Puthia Rajbari is a two-storied structure, bui...</td>\n",
       "      <td>পুঠিয়া রাজবাড়ী, নাটোর, রাজশাহী।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>রাজবাড়ীর নির্মাণশৈলী কেমন?</td>\n",
       "      <td>ভবনের সম্মুখ ভাগের স্তম্ভ, অলংকরন, কাঠের কাজ, ...</td>\n",
       "      <td>What is the architectural style of the palace?</td>\n",
       "      <td>The columns, decorations, woodwork, and the fl...</td>\n",
       "      <td>পুঠিয়া রাজবাড়ী, নাটোর, রাজশাহী।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>রাজবাড়ীর সম্মুখভাগ কিসের তৈরি?</td>\n",
       "      <td>ভবনের সম্মুখ ভাগের স্তম্ভ, অলংকরন, কাঠের কাজ, ...</td>\n",
       "      <td>What is the front of the palace made of?</td>\n",
       "      <td>The columns, decorations, woodwork, and the fl...</td>\n",
       "      <td>পুঠিয়া রাজবাড়ী, নাটোর, রাজশাহী।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Questions  \\\n",
       "0                    এই ছবিটি কিসের?   \n",
       "1             এটি কোন দিক রাজবাড়ীর?   \n",
       "2  পুঠিয়া রাজবাড়ী কয় তলা বিশিষ্ট?   \n",
       "3        রাজবাড়ীর নির্মাণশৈলী কেমন?   \n",
       "4    রাজবাড়ীর সম্মুখভাগ কিসের তৈরি?   \n",
       "\n",
       "                                             Answers  \\\n",
       "0   এই ছবিটি হলো পুঠিয়া রাজবাড়ী বা পাঁচআনি জমিদ...   \n",
       "1                            এটি রাজবাড়ীর সম্মুখভাগ   \n",
       "2  পুঠিয়া রাজবাড়ী দ্বিতল বিশিষ্ট এবং  ইন্দো ইউর...   \n",
       "3  ভবনের সম্মুখ ভাগের স্তম্ভ, অলংকরন, কাঠের কাজ, ...   \n",
       "4  ভবনের সম্মুখ ভাগের স্তম্ভ, অলংকরন, কাঠের কাজ, ...   \n",
       "\n",
       "                             Translated Questions  \\\n",
       "0                        What is this picture of?   \n",
       "1          Which direction of the palace is this?   \n",
       "2  How many stories does the Puthia Rajbari have?   \n",
       "3  What is the architectural style of the palace?   \n",
       "4        What is the front of the palace made of?   \n",
       "\n",
       "                                  Translated Answers  \\\n",
       "0  This picture is of the Puthia Rajbari or Panch...   \n",
       "1           This is the front section of the palace.   \n",
       "2  Puthia Rajbari is a two-storied structure, bui...   \n",
       "3  The columns, decorations, woodwork, and the fl...   \n",
       "4  The columns, decorations, woodwork, and the fl...   \n",
       "\n",
       "                  Title(region name)  \n",
       "0  পুঠিয়া রাজবাড়ী, নাটোর, রাজশাহী।  \n",
       "1  পুঠিয়া রাজবাড়ী, নাটোর, রাজশাহী।  \n",
       "2  পুঠিয়া রাজবাড়ী, নাটোর, রাজশাহী।  \n",
       "3  পুঠিয়া রাজবাড়ী, নাটোর, রাজশাহী।  \n",
       "4  পুঠিয়া রাজবাড়ী, নাটোর, রাজশাহী।  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"/kaggle/input/vqa-excel/VQADataset.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d8bed",
   "metadata": {
    "papermill": {
     "duration": 0.008115,
     "end_time": "2024-11-07T19:05:04.210587",
     "exception": false,
     "start_time": "2024-11-07T19:05:04.202472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Dataset\n",
    "Kannada dataset is created and uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "507bc009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T19:05:04.228467Z",
     "iopub.status.busy": "2024-11-07T19:05:04.227921Z",
     "iopub.status.idle": "2024-11-07T19:05:08.225096Z",
     "shell.execute_reply": "2024-11-07T19:05:08.224159Z"
    },
    "papermill": {
     "duration": 4.008861,
     "end_time": "2024-11-07T19:05:08.227525",
     "exception": false,
     "start_time": "2024-11-07T19:05:04.218664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Questions', 'Answers', 'Translated Questions', 'Translated Answers', 'Title(region name)'],\n",
      "    num_rows: 1646\n",
      "})\n",
      "100\n",
      "<start_of_turn>user\n",
      " উত্তর তৈরি করুন:\n",
      "\"এই ছবিটি কিসের?\"<end_of_turn>\n",
      "<start_of_turn>model\n",
      " এই ছবিটি হলো পুঠিয়া রাজবাড়ী বা পাঁচআনি জমিদারবাড়ী হচ্ছে মহারানী হেমন্তকুমারী দেবীর বাসভবন। বাংলার প্রত্নতাত্ত্বিক ঐতিহ্যের মধ্যে রাজশাহীর পুঠিয়া রাজবাড়ী অন্যতম।[১] ১৮৯৫ সালে মহারানী হেমন্তকুমারী দেবী আকর্ষনীয় ইন্দো ইউরোপীয় স্থাপত্যরীতিতে আয়তাকার দ্বিতল বর্তমান রাজবাড়ীটি নির্মাণ করেন।<end_of_turn >\n",
      "<start_of_turn>user\n",
      " উত্তর তৈরি করুন:\n",
      "\"এটি কোন দিক রাজবাড়ীর?\"<end_of_turn>\n",
      "<start_of_turn>model\n",
      "এটি রাজবাড়ীর সম্মুখভাগ<end_of_turn >\n",
      "<start_of_turn>user\n",
      " উত্তর তৈরি করুন:\n",
      "\"পুঠিয়া রাজবাড়ী কয় তলা বিশিষ্ট?\"<end_of_turn>\n",
      "<start_of_turn>model\n",
      "পুঠিয়া রাজবাড়ী দ্বিতল বিশিষ্ট এবং  ইন্দো ইউরোপীয় স্থাপত্যরীতিতে ১৮৯৫ সালে মহারানী হেমন্তকুমারী দেবী তার শাশুড়ি মহারানী শরৎ সুন্দরী দেবীর সম্মানে নির্মাণ করান।<end_of_turn >\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "import datasets\n",
    "\n",
    "tokenizer = keras_nlp.models.GemmaTokenizer.from_preset(model_id)\n",
    "\n",
    "from datasets import Dataset\n",
    "ds = Dataset.from_pandas(df)\n",
    "\n",
    "print(ds)\n",
    "\n",
    "data = ds.with_format(\"np\", columns=[\"Questions\", \"Answers\"], output_all_columns=False)\n",
    "train = []\n",
    "\n",
    "for x in data:\n",
    "  #item = f\"<start_of_turn>user\\n다음에 대한 이메일 답장을 작성해줘.\\n\\\"{x['input']}\\\"<end_of_turn>\\n<start_of_turn>model\\n{x['output']}<end_of_turn>\"\n",
    "    item = f\"<start_of_turn>user\\n উত্তর তৈরি করুন:\\n\\\"{x['Questions']}\\\"<end_of_turn>\\n<start_of_turn>model\\n{x['Answers']}<end_of_turn >\"\n",
    "\n",
    "    length = len(tokenizer(item))\n",
    "  # skip data if the token length is longer than our limit\n",
    "    if length < token_limit:\n",
    "        train.append(item)\n",
    "        if(len(train)>=num_data_limit):\n",
    "            break\n",
    "\n",
    "print(len(train))\n",
    "print(train[0])\n",
    "print(train[1])\n",
    "print(train[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26916651",
   "metadata": {
    "papermill": {
     "duration": 0.008142,
     "end_time": "2024-11-07T19:05:08.244078",
     "exception": false,
     "start_time": "2024-11-07T19:05:08.235936",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LoRA Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b8f22d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T19:05:08.261837Z",
     "iopub.status.busy": "2024-11-07T19:05:08.261268Z",
     "iopub.status.idle": "2024-11-07T19:05:08.653478Z",
     "shell.execute_reply": "2024-11-07T19:05:08.652429Z"
    },
    "papermill": {
     "duration": 0.403823,
     "end_time": "2024-11-07T19:05:08.656018",
     "exception": false,
     "start_time": "2024-11-07T19:05:08.252195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,617,270,528\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> (9.75 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,617,270,528\u001b[0m (9.75 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,928,640</span> (11.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,928,640\u001b[0m (11.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enable LoRA for the model and set the LoRA rank to 4.\n",
    "gemma_lm.backbone.enable_lora(rank=lora_rank)\n",
    "gemma_lm.summary()\n",
    "\n",
    "# Limit the input sequence length (to control memory usage).\n",
    "gemma_lm.preprocessor.sequence_length = token_limit\n",
    "# Use AdamW (a common optimizer for transformer models).\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=lr_value,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "# Exclude layernorm and bias terms from decay.\n",
    "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
    "\n",
    "gemma_lm.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=optimizer,\n",
    "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32219d8",
   "metadata": {
    "papermill": {
     "duration": 0.00944,
     "end_time": "2024-11-07T19:05:08.675431",
     "exception": false,
     "start_time": "2024-11-07T19:05:08.665991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save LoRA for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71610bea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T19:05:08.696284Z",
     "iopub.status.busy": "2024-11-07T19:05:08.695922Z",
     "iopub.status.idle": "2024-11-07T19:21:03.279584Z",
     "shell.execute_reply": "2024-11-07T19:21:03.278587Z"
    },
    "papermill": {
     "duration": 954.596737,
     "end_time": "2024-11-07T19:21:03.281550",
     "exception": false,
     "start_time": "2024-11-07T19:05:08.684813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m 83/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m12s\u001b[0m 726ms/step - loss: 1.4211 - sparse_categorical_accuracy: 0.4359\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "আমি দুঃখিত, আমি কোনও রাজবাড়ীর অবস্থান জানি না। আমি Google দ্বারা তৈরি একটি বৃহৎ ভাষা মডেল। আমি বিভিন্ন বিষয় সম্পর্কে তথ্য প্রদান করতে পারি, কিন্তু আমার কোনও স্থানের অবস্থান জানা নেই। \n",
      "<end_of_turn>\n",
      "TOTAL TIME ELAPSED: 18.51s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 790ms/step - loss: 1.3271 - sparse_categorical_accuracy: 0.4553\n",
      "Epoch 2/20\n",
      "\u001b[1m 82/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m9s\u001b[0m 513ms/step - loss: 0.7205 - sparse_categorical_accuracy: 0.6404\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "আমি তোমার প্রশ্নের উত্তর দিতে পারছি না। আমি এমন কোন তথ্য তৈরি করতে পারি না যা স্থাপনা বা জায়গার নির্দিষ্ট নাম বা অবস্থানের তথ্য প্রদান করে। <end_of_turn >\n",
      "TOTAL TIME ELAPSED: 3.19s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 453ms/step - loss: 0.6849 - sparse_categorical_accuracy: 0.6498\n",
      "Epoch 3/20\n",
      "\u001b[1m 85/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 485ms/step - loss: 0.5775 - sparse_categorical_accuracy: 0.6939\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "আমি তোমার প্রশ্নের উত্তর দিতে পারছি না। আমি এমন কোনও তথ্য তৈরি করতে পারি না যা রাজবাড়ীর দিক নির্ণয় করবে।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 2.56s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 438ms/step - loss: 0.5573 - sparse_categorical_accuracy: 0.6979\n",
      "Epoch 4/20\n",
      "\u001b[1m 85/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 485ms/step - loss: 0.5211 - sparse_categorical_accuracy: 0.7149\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "আমি তোমার প্রশ্নের উত্তর দিতে পারছি না। আমি এটি কোন দিক রাজবাড়ীর বুঝতে পারছি না।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 2.07s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 433ms/step - loss: 0.4972 - sparse_categorical_accuracy: 0.7229\n",
      "Epoch 5/20\n",
      "\u001b[1m 86/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 479ms/step - loss: 0.4699 - sparse_categorical_accuracy: 0.7420\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "এটি রাজবাড়ীর একটি ছবি।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 0.89s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 421ms/step - loss: 0.4516 - sparse_categorical_accuracy: 0.7454\n",
      "Epoch 6/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.4228 - sparse_categorical_accuracy: 0.7671\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "এটি রাজবাড়ীর একটি প্রধান ভবনের দরজা।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.20s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 424ms/step - loss: 0.4091 - sparse_categorical_accuracy: 0.7705\n",
      "Epoch 7/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.3726 - sparse_categorical_accuracy: 0.7913\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "এটি রাজবাড়ীর প্রধান ভবনের দরজার কাছাকাছি।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.43s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 427ms/step - loss: 0.3619 - sparse_categorical_accuracy: 0.7953\n",
      "Epoch 8/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.3254 - sparse_categorical_accuracy: 0.8176\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "এটি রাজবাড়ীর প্রধান ভবনের দরজা।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.16s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 424ms/step - loss: 0.3145 - sparse_categorical_accuracy: 0.8219\n",
      "Epoch 9/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.2840 - sparse_categorical_accuracy: 0.8453\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "এটি রাজবাড়ীর প্রধান প্রবেশদ্বার।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.12s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 423ms/step - loss: 0.2744 - sparse_categorical_accuracy: 0.8484\n",
      "Epoch 10/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.2444 - sparse_categorical_accuracy: 0.8687\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "এটি রাজবাড়ীর প্রধান প্রবেশদ্বার।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.12s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 424ms/step - loss: 0.2375 - sparse_categorical_accuracy: 0.8708\n",
      "Epoch 11/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.2104 - sparse_categorical_accuracy: 0.8909\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "এটি রাজবাড়ীর সম্মুখভাগের।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.05s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 423ms/step - loss: 0.2034 - sparse_categorical_accuracy: 0.8926\n",
      "Epoch 12/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.1794 - sparse_categorical_accuracy: 0.9142\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "এটি দরজার কাছাকাছি অবস্থিত একটি ঝরনার ছবি।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.50s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 427ms/step - loss: 0.1748 - sparse_categorical_accuracy: 0.9147\n",
      "Epoch 13/20\n",
      "\u001b[1m 86/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 479ms/step - loss: 0.1566 - sparse_categorical_accuracy: 0.9255\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "এটি রাজবাড়ীর সম্মুখভাগ।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.01s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 422ms/step - loss: 0.1535 - sparse_categorical_accuracy: 0.9259\n",
      "Epoch 14/20\n",
      "\u001b[1m 85/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 485ms/step - loss: 0.1329 - sparse_categorical_accuracy: 0.9416\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "এটি রাজবাড়ীরönster ।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 0.82s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 420ms/step - loss: 0.1307 - sparse_categorical_accuracy: 0.9418\n",
      "Epoch 15/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.1147 - sparse_categorical_accuracy: 0.9543\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "এটি রাজবাড়ীর সম্মুখভাগ।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.01s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 422ms/step - loss: 0.1132 - sparse_categorical_accuracy: 0.9541\n",
      "Epoch 16/20\n",
      "\u001b[1m 91/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 452ms/step - loss: 0.0990 - sparse_categorical_accuracy: 0.9615\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "এটি রাজবাড়ীর সম্মুখভাগ।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.01s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 422ms/step - loss: 0.0984 - sparse_categorical_accuracy: 0.9614\n",
      "Epoch 17/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.0901 - sparse_categorical_accuracy: 0.9652\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "এটি রাজবাড়ীর সম্মুখভাগের কক্ষের ছবি ।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.24s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 425ms/step - loss: 0.0892 - sparse_categorical_accuracy: 0.9647\n",
      "Epoch 18/20\n",
      "\u001b[1m 84/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 490ms/step - loss: 0.0820 - sparse_categorical_accuracy: 0.9675\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "এটি রাজবাড়ীর সম্মুখভাগ।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.01s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 422ms/step - loss: 0.0813 - sparse_categorical_accuracy: 0.9670\n",
      "Epoch 19/20\n",
      "\u001b[1m 84/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 490ms/step - loss: 0.0759 - sparse_categorical_accuracy: 0.9681 \n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "এটি রাজবাড়ীর সম্মুখভাগ।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.01s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 422ms/step - loss: 0.0753 - sparse_categorical_accuracy: 0.9678\n",
      "Epoch 20/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.0720 - sparse_categorical_accuracy: 0.9681\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "এটি কোন দিক রাজবাড়ীর?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "এটি রাজবাড়ীর সম্মুখভাগ।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.01s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 422ms/step - loss: 0.0716 - sparse_categorical_accuracy: 0.9680\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6VUlEQVR4nO3deXxU1f3/8ffMJJksZCVkJSEBZFEgLEoa0LqlIlK3fq0oPoTi0tZSfyraKm2FfmsrblW+VSrWinZTsVa0LYiFKC6IYtlUNlkCCYQkJCGZkJCZZOb+/kgyEElCJmRyM8nr+XjMI8mdc2c+l8uQN+eec67FMAxDAAAAJrGaXQAAAOjbCCMAAMBUhBEAAGAqwggAADAVYQQAAJiKMAIAAExFGAEAAKYijAAAAFMFmV1AR3g8HhUVFSkyMlIWi8XscgAAQAcYhqHq6mqlpKTIam27/yMgwkhRUZHS0tLMLgMAAHRCYWGhBg4c2ObzARFGIiMjJTUeTFRUlMnVAACAjnA4HEpLS/P+Hm9LQISR5kszUVFRhBEAAALM6YZYMIAVAACYijACAABMRRgBAACmIowAAABTEUYAAICpCCMAAMBUhBEAAGAqwggAADAVYQQAAJiKMAIAAExFGAEAAKYijAAAAFP16TDyp4/366evb9X+shqzSwEAoM/q02Hkjc2H9Np/D2rHYYfZpQAA0Gf16TCS2T9ckpRfTs8IAABm6dNhJCM+QpK4TAMAgIn6dBjJ9IaRWpMrAQCg7+rTYSSjf2MY4TINAADm6dthpKln5Ei1U8ecDSZXAwBA39Snw0h0WLD6R4RIYtwIAABm6dNhRDrRO5JPGAEAwBSEkf7MqAEAwEx9PoxkxrPWCAAAZurzYYS1RgAAMBdhpPkyTTlrjQAAYIY+H0aaFz6rqHGpqrbe5GoAAOh7+nwYibAHKSHSLolxIwAAmKHPhxGJcSMAAJiJMCIpsz9rjQAAYBbCiE7qGeEyDQAA3Y4wohNrjXCZBgCA7kcYUcsl4Q3DMLkaAAD6FsKITqw14qhrUEWNy+RqAADoWwgjkkKDbUqJDpXEuBEAALobYaTJiUs1rMQKAEB3Iow0Ya0RAADMQRhp4l1rhMs0AAB0K8JIE3pGAAAwh89h5IMPPtCVV16plJQUWSwWvfnmm6fdZ+3atRo/frzsdruGDh2ql156qROl+lcm03sBADCFz2GkpqZGWVlZWrx4cYfa5+fna9q0abr44ou1ZcsW3X333brtttv0zjvv+FysP6XHhctqkWpdbh2pdppdDgAAfUaQrztMnTpVU6dO7XD7JUuWKDMzU7/97W8lSSNHjtRHH32kp556SlOmTPH17f0mJMiq1NgwFVYcV35ZjRKiQs0uCQCAPsHvY0bWr1+v3NzcFtumTJmi9evXt7mP0+mUw+Fo8egOzYufsdYIAADdx+9hpLi4WImJiS22JSYmyuFw6Pjx463us3DhQkVHR3sfaWlp/i5T0snjRlhrBACA7tIjZ9PMmzdPVVVV3kdhYWG3vK+3Z4QZNQAAdBufx4z4KikpSSUlJS22lZSUKCoqSmFhYa3uY7fbZbfb/V3aKTIHcJkGAIDu5veekZycHOXl5bXYtnr1auXk5Pj7rX3mXfisrEYeD9N7AQDoDj6HkWPHjmnLli3asmWLpMapu1u2bFFBQYGkxkssM2fO9Lb/4Q9/qH379umnP/2pdu7cqd///vd67bXXdM8993TNEXShgbFhCrJa5GzwqNhRZ3Y5AAD0CT6Hkf/+978aN26cxo0bJ0maO3euxo0bp/nz50uSDh8+7A0mkpSZmakVK1Zo9erVysrK0m9/+1v98Y9/7FHTepsF2axKiwuXxLgRAAC6i89jRi666KJ2VyhtbXXViy66SJs3b/b1rUyR0T9c+WU1yi+v0aSh8WaXAwBAr9cjZ9OYiXvUAADQvQgjX8NaIwAAdC/CyNecCCPHTK4EAIC+gTDyNc0LnxVWHJeb6b0AAPgdYeRrUmLCFGKzyuX2qKiy9eXqAQBA1yGMfI3NalF6/8bpvfkMYgUAwO8II63g7r0AAHQfwkgrMuPpGQEAoLsQRlqRGd9PEmuNAADQHQgjrcigZwQAgG5DGGlF81ojhUePq97tMbkaAAB6N8JIKxIjQxUabJXbY+jgUab3AgDgT4SRVlitlhMzarhUAwCAXxFG2tAcRhg3AgCAfxFG2pA5gLVGAADoDoSRNmTSMwIAQLcgjLQhI54wAgBAdyCMtKF5rZGiyuNyNrhNrgYAgN6LMNKGAf3sigixyWNIhRW1ZpcDAECvRRhpg8ViOelSDWEEAAB/IYy0ozmMsNYIAAD+Qxhpx+CmMLKPMAIAgN8QRtrBKqwAAPgfYaQd3ss0LHwGAIDfEEba0Xz33sNVdTruYnovAAD+QBhpR2x4sKJCgyRJByroHQEAwB8II+2wWCze3hHGjQAA4B+EkdPIZK0RAAD8ijByGicWPjtmciUAAPROhJHTOHGZhp4RAAD8gTByGs1rjeQzvRcAAL8gjJxG82WaI9VOHXM2mFwNAAC9D2HkNKLDghUXESKJGTUAAPgDYaQDMlmJFQAAvyGMdIB33MgRwggAAF2NMNIBmfHhkhjECgCAPxBGOiCDVVgBAPAbwkgHNF+m2V/OWiMAAHQ1wkgHNPeMVNS4VHW83uRqAADoXQgjHdDPHqQBkXZJXKoBAKCrEUY6iOm9AAD4B2GkgzKbxo3sY3ovAABdijDSQRn0jAAA4BeEkQ5qXmuEMSMAAHQtwkgHNfeM5JfVyDAMk6sBAKD3IIx00KC4xjDiqGvQ0Vqm9wIA0FUIIx0UFmJTSnSopMbeEQAA0DUIIz44+VINAADoGoQRH3CPGgAAuh5hxAfNa41w914AALoOYcQH9IwAAND1CCM+OHmtEab3AgDQNQgjPkiLC5fVItW43DpyzGl2OQAA9AqEER/Yg2xKjQ2TJO0vqzW5GgAAegfCiI8ymgexlh0zuRIAAHqHToWRxYsXKyMjQ6GhocrOztaGDRvabb9o0SINHz5cYWFhSktL0z333KO6urpOFWy2TO9aI/SMAADQFXwOI8uWLdPcuXO1YMECbdq0SVlZWZoyZYpKS0tbbf/yyy/rgQce0IIFC7Rjxw698MILWrZsmX72s5+dcfFmaO4ZYUYNAABdw+cw8uSTT+r222/X7NmzdfbZZ2vJkiUKDw/X0qVLW23/8ccfa/LkyZoxY4YyMjJ02WWX6cYbbzxtb0pP1dwzsp+1RgAA6BI+hRGXy6WNGzcqNzf3xAtYrcrNzdX69etb3WfSpEnauHGjN3zs27dPK1eu1BVXXHEGZZsn46Qw4vEwvRcAgDMV5EvjsrIyud1uJSYmttiemJionTt3trrPjBkzVFZWpvPPP1+GYaihoUE//OEP271M43Q65XSemDrrcDh8KdOvBsaGKchqUV29RyXVdUqODjO7JAAAAprfZ9OsXbtWDz/8sH7/+99r06ZNeuONN7RixQo99NBDbe6zcOFCRUdHex9paWn+LrPDgm1WpcU1Ln6Wf4RLNQAAnCmfwkh8fLxsNptKSkpabC8pKVFSUlKr+zz44IO6+eabddttt2n06NG69tpr9fDDD2vhwoXyeDyt7jNv3jxVVVV5H4WFhb6U6XcZ/ZvCCONGAAA4Yz6FkZCQEE2YMEF5eXnebR6PR3l5ecrJyWl1n9raWlmtLd/GZrNJUptLqtvtdkVFRbV49CTcowYAgK7j05gRSZo7d65mzZqlc889VxMnTtSiRYtUU1Oj2bNnS5Jmzpyp1NRULVy4UJJ05ZVX6sknn9S4ceOUnZ2tPXv26MEHH9SVV17pDSWBhrVGAADoOj6HkenTp+vIkSOaP3++iouLNXbsWK1atco7qLWgoKBFT8gvfvELWSwW/eIXv9ChQ4c0YMAAXXnllfrNb37TdUfRzbxrjXCZBgCAM2YxAuD2sw6HQ9HR0aqqquoRl2wKK2p1wWPvKcRm1Y6HLpfNajG7JAAAepyO/v7m3jSdkBITphCbVS63R0WVx80uBwCAgEYY6QSb1aL05hk1DGIFAOCMEEY6iXEjAAB0DcJIJ2XG0zMCAEBXIIx0EmuNAADQNQgjnXTi7r2sNQIAwJkgjHRScxgprKhVvbv1Ze0BAMDpEUY6KTEyVKHBVjV4DB08yvReAAA6izDSSVar5cSMGsaNAADQaYSRM9AcRphRAwBA5xFGzoB3Rg1rjQAA0GmEkTMwOJ6eEQAAzhRh5AzQMwIAwJkjjJyBjKZVWA8dPS5ng9vkagAACEyEkTMwoJ9dESE2eYzG9UYAAIDvCCNnwGKxeC/V5JcRRgAA6AzCyBniHjUAAJwZwsgZymxea4RBrAAAdAph5Axl0jMCAMAZIYycIS7TAABwZggjZ6i5Z6Soqk7HXUzvBQDAV4SRMxQbHqyo0CBJ0oEKekcAAPAVYeQMWSwWxo0AAHAGCCNdgLVGAADoPMJIF6BnBACAziOMdIHmMMJaIwAA+I4w0gUymhc+o2cEAACfEUa6QPOYkSPVTh1zNphcDQAAgYUw0gWiw4IVFxEiiXEjAAD4ijDSRTL6h0uS9jNuBAAAnxBGukhmfD9J9IwAAOArwkgXyYxv7BlhrREAAHxDGOkiJxY+O2ZyJQAABBbCSBdpnt67v5yeEQAAfEEY6SLNPSMVNS5VHa83uRoAAAIHYaSL9LMHaUCkXRKDWAEA8AVhpAtlei/VEEYAAOgowkgX8t6jhp4RAAA6jDDShTK4ey8AAD4jjHShE2uNEEYAAOgowkgXyjjpMo1hGCZXAwBAYCCMdKFBcY1hxFHXoKO1TO8FAKAjCCNdKCzEpuToUElcqgEAoKMII10sk0GsAAD4hDDSxbwzalhrBACADiGMdLHmhc/20TMCAECHEEa6GGuNAADgG8JIF2tea2Q/03sBAOgQwkgXS4sLl9Ui1bjcOnLMaXY5AAD0eISRLmYPsik1NkyStL+s1uRqAADo+QgjfpDRn3EjAAB0FGHED7x372V6LwAAp0UY8YPmnpH8I4QRAABOhzDiB5ksfAYAQIcRRvzg5FVYPR6m9wIA0J5OhZHFixcrIyNDoaGhys7O1oYNG9ptX1lZqTlz5ig5OVl2u13Dhg3TypUrO1VwIBgYGyab1aK6eo9KquvMLgcAgB7N5zCybNkyzZ07VwsWLNCmTZuUlZWlKVOmqLS0tNX2LpdL3/rWt7R//369/vrr2rVrl55//nmlpqaecfE9VbDNqvS4xsXPuHsvAADt8zmMPPnkk7r99ts1e/ZsnX322VqyZInCw8O1dOnSVtsvXbpUFRUVevPNNzV58mRlZGTowgsvVFZW1hkX35Nl9G9eiZW1RgAAaI9PYcTlcmnjxo3Kzc098QJWq3Jzc7V+/fpW9/nnP/+pnJwczZkzR4mJiRo1apQefvhhud3uM6u8h2seN5JfdszkSgAA6NmCfGlcVlYmt9utxMTEFtsTExO1c+fOVvfZt2+f3n33Xd10001auXKl9uzZox/96Eeqr6/XggULWt3H6XTK6TyxlLrD4fClzB7Bu9YIPSMAALTL77NpPB6PEhIS9Ic//EETJkzQ9OnT9fOf/1xLlixpc5+FCxcqOjra+0hLS/N3mV3Ouwor03sBAGiXT2EkPj5eNptNJSUlLbaXlJQoKSmp1X2Sk5M1bNgw2Ww277aRI0equLhYLper1X3mzZunqqoq76OwsNCXMnuE5p6RgvJaVR2vN7kaAAB6Lp/CSEhIiCZMmKC8vDzvNo/Ho7y8POXk5LS6z+TJk7Vnzx55PB7vtq+++krJyckKCQlpdR+73a6oqKgWj0CTGhOmwfERcrk9euAfn8swWG8EAIDW+HyZZu7cuXr++ef1pz/9STt27NAdd9yhmpoazZ49W5I0c+ZMzZs3z9v+jjvuUEVFhe666y599dVXWrFihR5++GHNmTOn646iB7JaLXpq+lgFWS16+8tivbyhwOySAADokXwawCpJ06dP15EjRzR//nwVFxdr7NixWrVqlXdQa0FBgazWExknLS1N77zzju655x6NGTNGqampuuuuu3T//fd33VH0UFlpMbr/8hH6zcod+tW/tmvCoFiNSAq8Xh4AAPzJYgTA9QOHw6Ho6GhVVVUF3CUbj8fQLX/6TGt3HdHQhH76548nKzzE5wwIAEDA6ejvb+5N42dWq0VPfDdLCZF27Sk9pl/9a7vZJQEA0KMQRrpBfD+7Fk0fK4tFevWzQv1za5HZJQEA0GMQRrrJpKHx+vHFQyVJP3vjCxWUsxgaAAASYaRb3XXpWTp3UKyOORt05yub5GrwnH4nAAB6OcJINwqyWfV/N45TdFiwth6s0hP/2WV2SQAAmI4w0s1SY8L02HVjJEl/+GCf3ttVanJFAACYizBiginnJGlWziBJ0r2vbVWJo87kigAAMA9hxCTzrhipkclRqqhx6Z5lW+T29PjlXgAA8AvCiElCg216ZsY4hYfY9PHecj27do/ZJQEAYArCiImGDOinX109SpL01Jrd+mx/hckVAQDQ/QgjJvuf8am6dlyq3B5Dd72yWZW1LrNLAgCgWxFGTGaxWPTQNaOU0T9cRVV1+unrnysAbhcEAECXIYz0AP3sQXpmxngF2yz6z/YS/eWTA2aXBABAtyGM9BCjUqM1b+pISdKv/71D24qqTK4IAIDuQRjpQWZPztClIxLkcnt05yubVeNsMLskAAD8jjDSg1gsFj3+3SwlRYVq35EaLfjnNrNLAgDA7wgjPUxcRIgW3TBWVov0+saDWr75oNklAQDgV4SRHugbg/vr/116liTpF8u/VH5ZjckVAQDgP4SRHurOS85Sdmacalxu3fnKJjkb3GaXBACAXxBGeiib1aJFN4xVbHiwvjzk0KNv7zK7JAAA/IIw0oMlR4fp8euyJElL1+VrzfYSkysCAKDrEUZ6uNyzEzV7coYk6Sevb9XhquPmFgQAQBcjjASAB6aO0DkpUTpaW6+7Xt0it4fl4gEAvQdhJADYg2x6ZsZ4RYTYtCG/Qk+/u9vskgAA6DKEkQCRGR+hX187SpL0u7zd+mRfuckVAQDQNQgjAeTacQP1P+MHymNId7+6RRU1LrNLAgDgjBFGAsyvrj5Hg+MjVOyo00/+vlWGwfgRAEBgI4wEmAh7kJ6eMU4hNqvydpbqqTW75WFAKwAggBFGAtA5KdH6+bSRkhrHj9y89FMVVTLlFwAQmAgjAWpmziA9dM0ohQZbtW5PuaYs+kBvbDrIZRsAQMAhjAQoi8Wim78xSCv/3wUamxaj6roGzX1tq370t00MbAUABBTCSIAbPKCfXv9hju791jAFWS16+8tiTVn0gd7dydLxAIDAQBjpBYJsVt156Vla/qPJGprQT0eqnbrlpf9q3htfqMbZYHZ5AAC0izDSi4weGK1/33m+bpmcKUl6ZUOBpv7fh/rv/gqTKwMAoG2EkV4mNNim+VeerZdvz1ZKdKgKKmp1/XPr9eiqnXI1eMwuDwCAUxBGeqlJQ+K16p5v6jvjU+UxpGfX7tXVi9dpZ7HD7NIAAGiBMNKLRYUG68nrx+rZm8YrNjxYOw47dNXT6/SHD/Zy518AQI9BGOkDpo5O1jv3fFOXjkiQy+3Rwyt36sbnP1FhRa3ZpQEAQBjpKxIiQ/XHWefqke+MVniITRvyK3T5og/02meFLJQGADAVYaQPsVgsumFiulbd9U2dOyhWNS63fvqPz3X7nzeq7JjT7PIAAH0UYaQPSu8frmU/yNH9l49QsM2iNTtKNOWpD/SfbcVmlwYA6IMII32UzWrRHRcN0VtzzteIpEiV17j0/b9s1H1/36rqunqzywMA9CGEkT7u7JQovfXjyfrBhYNlsUivbzyoyxd9qE/2lZtdGgCgjyCMQPYgm+ZNHall389RWlyYDlUe143Pf6LfrNiuunq32eUBAHo5wgi8JmbG6e27vqnp56bJMKTnP8zXpb99X//aWsSMGwCA3xBG0EI/e5AevW6M/jjzXKVEh+pQ5XHd+cpmfXfJen1+sNLs8gAAvZDFCID/8jocDkVHR6uqqkpRUVFml9NnHHe59YcP9mnJ+3t1vOlyzXUTBuqnU4YrISrU5OoAAD1dR39/E0ZwWoerjuvRt3fqzS1FkqTwEJvmXDxUt56fqdBgm8nVAQB6KsIIutymgqP61b+2a0thpSRpYGyYfnbFSE0dlSSLxWJucQCAHocwAr/weAz9c2uRHnl7p4oddZIaB77O//bZGpUabXJ1AICehDACv6p1NWjJ+/v03Pt75WzwyGKRrp+QpvumDNeASLvZ5QEAegDCCLrFocrG8ST/3No4nqSfPUhzLh6qW87PkD2I8SQA0JcRRtCtNh6o0P/+a7s+P1glSUqPC9fPrhipKeckMp4EAPoowgi6ncdj6I3Nh/TYqp0qrW68C3DO4P568Ntn6+wUzhsA9DWEEZimxtmgZ9fu1R8+3CdXg0dWizT9vHTde9kwxfdjPAkA9BUd/f3dqRVYFy9erIyMDIWGhio7O1sbNmzo0H6vvvqqLBaLrrnmms68LQJEhD1I900Zrry5F2ramGR5DOmVDQW6+PG1+sMHe+Vq8JhdIgCgB/E5jCxbtkxz587VggULtGnTJmVlZWnKlCkqLS1td7/9+/frvvvu0wUXXNDpYhFY0uLCtXjGeL32gxyNSo1StbNBD6/cqcueel+rt5dwvxsAgKROXKbJzs7Weeedp2eeeUaS5PF4lJaWpjvvvFMPPPBAq/u43W5985vf1C233KIPP/xQlZWVevPNNzv8nlymCXxuj6F/bDyox97ZpbJjjeNJzh8ar59PG6mRyZxTAOiN/HKZxuVyaePGjcrNzT3xAlarcnNztX79+jb3+9WvfqWEhATdeuutvrwdehGb1aLrz0vT2p9cpDsuGqIQm1Uf7SnTtN99qAf+8blKq+vMLhEAYBKfwkhZWZncbrcSExNbbE9MTFRxcXGr+3z00Ud64YUX9Pzzz3f4fZxOpxwOR4sHeod+9iDdf/kIrZl7oaaNbhxP8upnhbr48bV65t3dqmu6IR8AoO/o1ADWjqqurtbNN9+s559/XvHx8R3eb+HChYqOjvY+0tLS/FglzJDeP1yLbxqv13+Yo6y0GNW43HriP1/pkifW6s3Nh+TxMJ4EAPoKn8aMuFwuhYeH6/XXX28xI2bWrFmqrKzUW2+91aL9li1bNG7cONlsJ1bi9HgaZ1JYrVbt2rVLQ4YMOeV9nE6nnE6n92eHw6G0tDTGjPRSHo+hf31epEff3qmiqsbLNVkDo/WLb5+t8zLiTK4OANBZfhkzEhISogkTJigvL8+7zePxKC8vTzk5Oae0HzFihL744gtt2bLF+7jqqqt08cUXa8uWLW32eNjtdkVFRbV4oPeyWi26emyq3r3vIv1kynBFhNi09WCVvrtkvX70t40qKK81u0QAgB8F+brD3LlzNWvWLJ177rmaOHGiFi1apJqaGs2ePVuSNHPmTKWmpmrhwoUKDQ3VqFGjWuwfExMjSadsB0KDbZpz8VB999yBemr1bi37rEArvyjWmu2l+t7kDM25eKiiw4LNLhMA0MV8DiPTp0/XkSNHNH/+fBUXF2vs2LFatWqVd1BrQUGBrFa/DkVBL5cQGaqF3xmtWZMG6TcrdujD3WX6wwf79Pf/Fuqebw3TjRPTFWzj7xgA9BYsB48ezTAMrf3qiH6zYof2lB6TJA0ZEKGfTxupi4cncBM+AOjBuDcNepUGt0evfFaop1Z/pYoalyQWTQOAno4wgl7JUVevxe/t0Ysf7ZfL7ZHFIl0/IU33XjZMCVGhZpcHADgJYQS9WmFFrR5ZtVMrPj8sSQoPsemOC4fotgsGKyzEdpq9AQDdgTCCPmHjgQo99O8d2lJYKUlKjg7VTy8frquzUmW1Mp4EAMxEGEGfYRiG/vX5YT369k4dqjwuSRozMFoPsmgaAJiKMII+p67eraXr8vX79/bqmLNBkjRtdLIemDpCaXHhJlcHAH0PYQR91pFqp55c/ZWWfVYgjyGFBFl16/mZ+tFFQxQZyqJpANBdCCPo83YcdujXK7Zr3Z5ySVJ8P7t+MmWYrpuQJhvjSQDA7wgjgBrHk6zZUaqHV+5QflmNJOns5Cg9+O2zlTOkv8nVAUDvRhgBTuJq8OjP6/fr//J2q7qucTzJlHMS9bMrRmpQ/wiTqwOA3okwArSiosalRWu+0t8+LZDbYyjYZtHsyZn68SVDFcV4EgDoUoQRoB27S6r10Iod+uCrI5Kk/hEhuudbw3TDeWkK4iZ8ANAlCCNAB7y3q1S//vd27T3SOJ5keGKkHvz22Tr/rHiTKwOAwEcYATqo3u3Ry58W6Kk1X6mytl6SlDsyQT+7YqQGD+hncnUAELgII4CPKmtd+r+83frL+gNq8BgKslo0MydDd116lqLDGU8CAL4ijACdtPfIMT28YofydpZKkmLCg3VP7jDNyE5XMONJAKDDCCPAGfrgqyP69Yrt+qrkmCRpaEI//WLaSF00PMHkygAgMBBGgC7Q4Pbo1c8K9eTqr1RR45IkXTR8gH4xbaSGJkSaXB0A9GyEEaALVR2v1zPv7tZLH+9XvduQzWrRjInp+n+XnqUBkXazywOAHokwAvjB/rIaPbxyh/6zvUSSFBFi0w8uHKLbLshUeEiQydUBQM9CGAH86JN95Xp45Q59frBKkpQQadfcbw3TdRMGsmgaADQhjAB+5vEYWvHFYT32zk4VVhyXJJ2V0E8PTB2hS0YkyGLhzsAA+jbCCNBNnA1u/e2TAv3u3d3eRdO+MThO86aOVFZajLnFAYCJCCNAN6s6Xq9n1+7V0nX5cjV4JElXZqXoJ5cNV3r/cJOrA4DuRxgBTHKo8rie/M9XemPzQRmGFGyz6OZvZOjOS4YqNiLE7PIAoNsQRgCTbSuq0iNv79SHu8skSZGhQfrRRUM1e3KGQoNtJlcHAP5HGAF6iA++OqKFb+/UjsMOSVJKdKjuvWy4rhmXKpuVQa4Aei/CCNCDeDyG3txySE+8s0tFVXWSpJHJUZo3dYS+OWyAydUBgH8QRoAeqK7erZc+3q/F7+1RdV2DJOmCs+L1wNQROicl2uTqAKBrEUaAHuxojUvPvLdHf17fuLy8xSJdOy5V9142XKkxYWaXBwBdgjACBICC8lo9/p9d+tfWIklSSJBVsydn6EcXDVV0WLDJ1QHAmSGMAAFka2GlHl65Q5/mV0iSYsKDdceFQzQzJ0NhIcy8ARCYCCNAgDEMQ+/tKtXClTu1u/SYpMZ73tx5yVBNPy9dIUHc8wZAYCGMAAGqwe3R8s2HtGjNbh2qbLznzcDYMN2dO0zXMh0YQAAhjAABztng1rLPCvX0u3t0pNopSRqa0E/3fmuYLh+VxI34APR4hBGglzjucutP6/fr2bV7VXW88UZ8o1Ojde9lw3ThsAGEEgA9FmEE6GUcdfX644f5euHDfapxuSVJEzPidN+U4ZqYGWdydQBwKsII0EuVH3Pq2bV79edPDnjvDnzhsAG677LhGj2QhdMA9ByEEaCXO1x1XE+/u0evfVaoBk/jx3jqqCTN/dYwnZUYaXJ1AEAYAfqMA+U1WrRmt97cckiGIVkt0rXjBuru3LOUFhdudnkA+jDCCNDH7Cqu1pOrd+mdbSWSpGCbRTecl647LxmqhKhQk6sD0BcRRoA+amthpZ74zy59uLtMkhQabNWsnAz98MIhio0IMbk6AH0JYQTo49bvLdcT/9mljQeOSpL62YN02wWZuvX8TEWGct8bAP5HGAEgwzC0dtcRPf7OLm0/7JAkxYYH6wcXDtGM7HRFEUoA+BFhBICXx2Po7S+L9dvVu7TvSI0kKSLEpusmDNT3JmcqMz7C5AoB9EaEEQCnaL7vzfMf7tNXJY0347NYpIuHJ+iWyZmaPLQ/K7oC6DKEEQBtMgxDH+8t19KP8pW3s9S7fVhiP82enKlrxqYqLMRmYoUAegPCCIAOyS+r0Z8+3q+//7fQu8x8THiwZkxM1805g5QcHWZyhQACFWEEgE8cdfV67bNCvfTxfh08elySFGS1aOroZM2enKHx6bEmVwgg0BBGAHSK22NozY4SLf0oX5/mV3i3j02L0ezJGbpidLKCbVYTKwQQKAgjAM7YtqIqvbhuv/65pUgud+NN+ZKiQnVzziDNmJjOImoA2kUYAdBljlQ79fKnBfrLJwdUdswpSbIHWfWd8an63qRMDU/ixnwATkUYAdDlnA1urfj8sJauy9eXhxze7ZOH9tctkzN18fAEWa1MDQbQiDACwG8Mw9B/DxzV0o/y9c62Ynma/hXJ6B+u703K0HXnpqmfPcjcIgGYjjACoFscPFqrP68/oFc3FMhR1yCpcXXXq8am6qbsdI1KjTa5QgBmIYwA6FY1zga9semgXvx4v3fJeUkanRqtGdnpuiorRRH0lgB9Skd/f3dqft7ixYuVkZGh0NBQZWdna8OGDW22ff7553XBBRcoNjZWsbGxys3Nbbc9gMAUYQ/SzTkZypt7oV79/jd0VVaKQmxWfXGoSvPe+EITf7NGP1v+hb48VGV2qQB6GJ97RpYtW6aZM2dqyZIlys7O1qJFi/T3v/9du3btUkJCwintb7rpJk2ePFmTJk1SaGioHn30US1fvlzbtm1Tampqh96TnhEgMFXUuPSPjQf1yoYC7Ss70VsyZmC0ZkxM15X0lgC9mt8u02RnZ+u8887TM888I0nyeDxKS0vTnXfeqQceeOC0+7vdbsXGxuqZZ57RzJkzO/SehBEgsBmGofX7yvXypwV6Z1ux6t2N/+z0swfp6rEpmpGdrnNSGFsC9DYd/f3t039JXC6XNm7cqHnz5nm3Wa1W5ebmav369R16jdraWtXX1ysuLq7NNk6nU06n0/uzw+Fosy2Ans9isWjSkHhNGhKv8mNOvd7UW7K/vFZ/+7RAf/u0QFlpMZoxMU1XZqUoPITeEqAv8WnMSFlZmdxutxITE1tsT0xMVHFxcYde4/7771dKSopyc3PbbLNw4UJFR0d7H2lpab6UCaAH69/Prh9cOETv3nuRXr4tW9PGJCvYZtHWwkrd/48vlP2bPD345pfaXsR/QoC+olv/+/HII4/o1Vdf1dq1axUaGtpmu3nz5mnu3Lnenx0OB4EE6GWsVosmDY3XpKHxKjupt+RAea3+8skB/eWTAxqbFqMZE9P17axkekuAXsynT3d8fLxsNptKSkpabC8pKVFSUlK7+z7xxBN65JFHtGbNGo0ZM6bdtna7XXa73ZfSAASw+H52/fDCIfr+BYP18d5yvbKhcWzJlsJKbSms1EP/3q5rx6fqxonpGpnMuDGgt/HpMk1ISIgmTJigvLw87zaPx6O8vDzl5OS0ud9jjz2mhx56SKtWrdK5557b+WoB9GpWq0XnnxWvxTeN1/p5l+qnlw9Xely4qp0N+vP6A5r6fx/q2t+v08ufFqiqtt7scgF0kU5N7Z01a5aee+45TZw4UYsWLdJrr72mnTt3KjExUTNnzlRqaqoWLlwoSXr00Uc1f/58vfzyy5o8ebL3dfr166d+/fp16D2ZTQP0XR6PoXV7y/TypwVavb1EDU1rz4fYrLpkRIKuHZ+qi4cnKCSoU8smAfAjv8ymkaTp06fryJEjmj9/voqLizV27FitWrXKO6i1oKBAVuuJfxSeffZZuVwuXXfddS1eZ8GCBfrlL3/p69sD6GOsVosuOGuALjhrgEqr6/TGpkNavumQdpVUa9W2Yq3aVqyY8GBNG52s74xP1fj0WFks3KwPCCQsBw8g4BiGoR2Hq7V880G9taVIpdUnlgJIjwvXNeNSde24VGXGR5hYJQDuTQOgT3B7DH28t0zLNx/Sqi+LVetye58bmxaj74xP1bfHpCguIsTEKoG+iTACoM+pdTXoP9tKtHzzIX24+4iahpcoyGrRRcMH6NpxA3XpyASFBtvMLRToIwgjAPq00uo6/WvrYS3ffFBfHjqxgFqkPUhXjE7WteNTNTEjTlYr40sAfyGMAECT3SXVWr75kN7aUqRDlce921NjwnT12BR9Z3yqhiZEmlgh0DsRRgDgazweQxv2V2j5pkNa+cVhVTsbvM+NSo3SteMG6sqsZCVEtr1CNICOI4wAQDvq6t3K21Gq5ZsPae2uUu/6JRaLdE5KVNON/fprYmYcS9EDnUQYAYAOqqhxacXnRXpj8yFtLqhs8VywzaJxabGaNLS/Jg+N19i0GAXbWGAN6AjCCAB0QqmjTh/vLde6PWX6eG95izEmkhQeYtPEzDhNHhKvSUP7a2RSFINggTYQRgDgDBmGoYKKWq3bU651e8u0fm+5KmpcLdrERYQoZ3D/xp6TIfEa1D+cFWCBJoQRAOhiHo+hncXV+nhvmdbtKdOG/ArVnLTImtQ4Q2fSkMZLOpOG9FdCFINh0XcRRgDAz+rdHm0trPT2nGwuOKp6d8t/Uocm9NPkIf01aWi8vjG4v6LDgk2qFuh+hBEA6Ga1rgZ9tv+oPm4ab/JlUZVO/hfWapFGpUZrYkacJmbG6byMOMWyTD16McIIAJisstalT/aVe3tO9h2pOaXNsMR+3mCSndlfSdFc1kHvQRgBgB7mcNVxbciv0Kf5Ffosv0K7S4+d0iY9LrwpmDT2njAgFoGMMAIAPVz5Mac+239Un+2v0Ib8Cm0rqvLe3K/ZgEi7JmY2hpPzMuI0PDGSqcQIGIQRAAgw1XX12lRQqQ355dqQX6GthVVyuT0t2kSHBeu8jFid1zTuZFRqNIuwoccijABAgKurd2trYaU25Fdow/4KbTxwVLVfm0ocFmzT+EExmpjRX+dlxmpcWqzCQmwmVQy0RBgBgF6mwe3RtiKHN5x8tr9ClbX1LdrYrBaNTI7UuLRYjR8Uo3FpsYw7gWkIIwDQy3k8hnaXHtOGpjEnG/LLVeJwntIuLiJE49JiNH5QrMalxWhMWoz62bn5H/yPMAIAfYxhGDpcVadNBUe1uaBSmwuO6stDjlPGnVgt0rDESI1Lj9X49BiNS4/V4PgIBsaiyxFGAAByNri1vcihTU3hZHNB5Sk3/5MaB8aOTYvR+PRYjUuPUVZaDKvF4owRRgAArSpx1Hl7TjYXVOrzQ5Wqq2/Ze2KxSEMH9NO49OaAEquzEvrRewKfEEYAAB1S7/Zo5+FqbS48qk0HjmpzYaUOlNee0q6fPUgjkyM1MjlKI5KiNDI5UsOTIhUewvgTtI4wAgDotPJjzsbek8Kj2nSgUlsPVp4yrVhq7EHJ6B+hEUnNIaXx68DYMGbwgDACAOg6bo+h3aXV2nm4WjsOO7SjuPHrkepTZ+9IUqQ9SCOSI5t6UKKavqcXpa8hjAAA/K7smFM7D1drZ7FD2w87tPNwtfaUHjtlBo/U2IsyKC68xWUeelF6N8IIAMAU9W6P9h2paepBcWjH4WrtPOxQaTu9KMOTIjUsKVKpMWFKjQlTcnSoUmLClBQdynL3AYwwAgDoUcqPObWz6fLOjqbLPW31ojSzWKTEyFAlxzSGk5ODSmpMmFJiwhQbHkzPSg9FGAEA9HjNvSg7ix3aW3pMRVV1Kqo83vioqpOroe2g0iw02KqU6MZg8vWgkhwTqpToMO7XY5KO/v5mJBEAwDTBNquGJzVOEf46j8dQeY1Lh6saw8mhyjodrjyuoqrG74sqj+tItVN19R7tK6vRvrKaNt8nLiJESVGhSoyyKzEqVAlRoV/72a7+EXbZWEfFFIQRAECPZLVaNCDSrgGRdo0ZGNNqG2eDWyVVTh1q6k05fFJQaX7UuNyqqHGposal7Yfbfj+b1aIB/exKjLIroTmoRIYqMTpUiSf9HMNloS5HGAEABCx7kE3p/cOV3j+81ecNw5CjrkFFlcdV7KhTqaNOJQ6nShx1TY/G78uOOeX2GCp21KnYUSepqs33DLFZldDUo5IYZVdCZGNY6R8RopjwYMVGhCgmLFgx4Y0/MwD39AgjAIBey2KxKDosWNFhwRqZ3PaYhQa3R+U1rhYBpTm4FDcFl9JqpypqXHK5PTp49LgOHj31Hj+tibQHKTo8WLFN4SQmPESxLb42f9/0c1iIIkOD+tTS+4QRAECfF2SzNvV0hLbbztng1pFqp0oczqawUqeSaqdKqup0tNalo7X1qmz66qirl2FI1c4GVTsbOhxepMY7Kzf3rDT3svSzBynCblN4SJAiQmwKtwcpwt70fUjjc40/Byk8pOl7u00hNmuPv6xEGAEAoIPsQTYNjA3XwNjWLwudzO0x5Dher6O1LlUebwopNY0/VzVtbw4vlbX1qqxt3FbrcstjyDvO5UwFWS0nhZNTw0tzuJmZk9Hm5S5/I4wAAOAHNqtFsREhio0I8Wk/Z4NbVbX1OtoUTipr61V13KUap1s1zgbVuNyqdTWoxtn49ZizQbWuxueav9a4Grx3Ym7wNI6bcdQ1tPu+08YkE0YAAEBj70tClE0Jp7lkdDpuj6FaV2NAOeZsUK3TrRpXQ1OAcau2Odg0fU2JCeuiI/AdYQQAgF7IZrUoMjRYkaHBSjS7mNNgvhEAADAVYQQAAJiKMAIAAExFGAEAAKYijAAAAFMRRgAAgKkIIwAAwFSEEQAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAApiKMAAAAUwXEXXsNw5AkORwOkysBAAAd1fx7u/n3eFsCIoxUV1dLktLS0kyuBAAA+Kq6ulrR0dFtPm8xThdXegCPx6OioiJFRkbKYrF02es6HA6lpaWpsLBQUVFRXfa6PVVfOl6OtffqS8fLsfZefeV4DcNQdXW1UlJSZLW2PTIkIHpGrFarBg4c6LfXj4qK6tV/Gb6uLx0vx9p79aXj5Vh7r75wvO31iDRjACsAADAVYQQAAJiqT4cRu92uBQsWyG63m11Kt+hLx8ux9l596Xg51t6rrx3v6QTEAFYAANB79emeEQAAYD7CCAAAMBVhBAAAmIowAgAATNXrw8jixYuVkZGh0NBQZWdna8OGDe22//vf/64RI0YoNDRUo0eP1sqVK7up0jOzcOFCnXfeeYqMjFRCQoKuueYa7dq1q919XnrpJVkslhaP0NDQbqq48375y1+eUveIESPa3SdQz2tGRsYpx2qxWDRnzpxW2wfaOf3ggw905ZVXKiUlRRaLRW+++WaL5w3D0Pz585WcnKywsDDl5uZq9+7dp31dXz/33aG9Y62vr9f999+v0aNHKyIiQikpKZo5c6aKiorafc3OfBa6w+nO6/e+971T6r788stP+7o98bxKpz/e1j7DFotFjz/+eJuv2VPPrb/06jCybNkyzZ07VwsWLNCmTZuUlZWlKVOmqLS0tNX2H3/8sW688Ubdeuut2rx5s6655hpdc801+vLLL7u5ct+9//77mjNnjj755BOtXr1a9fX1uuyyy1RTU9PuflFRUTp8+LD3ceDAgW6q+Mycc845Ler+6KOP2mwbyOf1s88+a3Gcq1evliR997vfbXOfQDqnNTU1ysrK0uLFi1t9/rHHHtPvfvc7LVmyRJ9++qkiIiI0ZcoU1dXVtfmavn7uu0t7x1pbW6tNmzbpwQcf1KZNm/TGG29o165duuqqq077ur58FrrL6c6rJF1++eUt6n7llVfafc2eel6l0x/vycd5+PBhLV26VBaLRf/zP//T7uv2xHPrN0YvNnHiRGPOnDnen91ut5GSkmIsXLiw1fbXX3+9MW3atBbbsrOzjR/84Ad+rdMfSktLDUnG+++/32abF1980YiOju6+orrIggULjKysrA63703n9a677jKGDBlieDyeVp8P1HNqGIYhyVi+fLn3Z4/HYyQlJRmPP/64d1tlZaVht9uNV155pc3X8fVzb4avH2trNmzYYEgyDhw40GYbXz8LZmjtWGfNmmVcffXVPr1OIJxXw+jYub366quNSy65pN02gXBuu1Kv7RlxuVzauHGjcnNzvdusVqtyc3O1fv36VvdZv359i/aSNGXKlDbb92RVVVWSpLi4uHbbHTt2TIMGDVJaWpquvvpqbdu2rTvKO2O7d+9WSkqKBg8erJtuukkFBQVttu0t59Xlcumvf/2rbrnllnZvGBmo5/Tr8vPzVVxc3OLcRUdHKzs7u81z15nPfU9VVVUli8WimJiYdtv58lnoSdauXauEhAQNHz5cd9xxh8rLy9ts25vOa0lJiVasWKFbb731tG0D9dx2Rq8NI2VlZXK73UpMTGyxPTExUcXFxa3uU1xc7FP7nsrj8ejuu+/W5MmTNWrUqDbbDR8+XEuXLtVbb72lv/71r/J4PJo0aZIOHjzYjdX6Ljs7Wy+99JJWrVqlZ599Vvn5+brgggtUXV3davvecl7ffPNNVVZW6nvf+16bbQL1nLam+fz4cu4687nvierq6nT//ffrxhtvbPcmar5+FnqKyy+/XH/+85+Vl5enRx99VO+//76mTp0qt9vdavvecl4l6U9/+pMiIyP1ne98p912gXpuOysg7toL38yZM0dffvnlaa8v5uTkKCcnx/vzpEmTNHLkSD333HN66KGH/F1mp02dOtX7/ZgxY5Sdna1Bgwbptdde69D/NgLVCy+8oKlTpyolJaXNNoF6TnFCfX29rr/+ehmGoWeffbbdtoH6Wbjhhhu8348ePVpjxozRkCFDtHbtWl166aUmVuZ/S5cu1U033XTageWBem47q9f2jMTHx8tms6mkpKTF9pKSEiUlJbW6T1JSkk/te6If//jH+ve//6333ntPAwcO9Gnf4OBgjRs3Tnv27PFTdf4RExOjYcOGtVl3bzivBw4c0Jo1a3Tbbbf5tF+gnlNJ3vPjy7nrzOe+J2kOIgcOHNDq1at9vrX86T4LPdXgwYMVHx/fZt2Bfl6bffjhh9q1a5fPn2MpcM9tR/XaMBISEqIJEyYoLy/Pu83j8SgvL6/F/xxPlpOT06K9JK1evbrN9j2JYRj68Y9/rOXLl+vdd99VZmamz6/hdrv1xRdfKDk52Q8V+s+xY8e0d+/eNusO5PPa7MUXX1RCQoKmTZvm036Bek4lKTMzU0lJSS3OncPh0KefftrmuevM576naA4iu3fv1po1a9S/f3+fX+N0n4We6uDBgyovL2+z7kA+ryd74YUXNGHCBGVlZfm8b6Ce2w4zewStP7366quG3W43XnrpJWP79u3G97//fSMmJsYoLi42DMMwbr75ZuOBBx7wtl+3bp0RFBRkPPHEE8aOHTuMBQsWGMHBwcYXX3xh1iF02B133GFER0cba9euNQ4fPux91NbWett8/Xj/93//13jnnXeMvXv3Ghs3bjRuuOEGIzQ01Ni2bZsZh9Bh9957r7F27VojPz/fWLdunZGbm2vEx8cbpaWlhmH0rvNqGI2zBtLT043777//lOcC/ZxWV1cbmzdvNjZv3mxIMp588klj8+bN3hkkjzzyiBETE2O89dZbxueff25cffXVRmZmpnH8+HHva1xyySXG008/7f35dJ97s7R3rC6Xy7jqqquMgQMHGlu2bGnxGXY6nd7X+Pqxnu6zYJb2jrW6utq47777jPXr1xv5+fnGmjVrjPHjxxtnnXWWUVdX532NQDmvhnH6v8eGYRhVVVVGeHi48eyzz7b6GoFybv2lV4cRwzCMp59+2khPTzdCQkKMiRMnGp988on3uQsvvNCYNWtWi/avvfaaMWzYMCMkJMQ455xzjBUrVnRzxZ0jqdXHiy++6G3z9eO9++67vX82iYmJxhVXXGFs2rSp+4v30fTp043k5GQjJCTESE1NNaZPn27s2bPH+3xvOq+GYRjvvPOOIcnYtWvXKc8F+jl97733Wv1723xMHo/HePDBB43ExETDbrcbl1566Sl/DoMGDTIWLFjQYlt7n3uztHes+fn5bX6G33vvPe9rfP1YT/dZMEt7x1pbW2tcdtllxoABA4zg4GBj0KBBxu23335KqAiU82oYp/97bBiG8dxzzxlhYWFGZWVlq68RKOfWXyyGYRh+7XoBAABoR68dMwIAAAIDYQQAAJiKMAIAAExFGAEAAKYijAAAAFMRRgAAgKkIIwAAwFSEEQAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAApvr/gLN6fsOaVFgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        model_name = f\"/kaggle/working/{lora_name}_{lora_rank}_epoch{epoch+1}.lora.h5\"\n",
    "        gemma_lm.backbone.save_lora_weights(model_name)\n",
    "\n",
    "        # Evaluate\n",
    "        text_gen(\"এটি কোন দিক রাজবাড়ীর?\")\n",
    "\n",
    "history = gemma_lm.fit(train, epochs=train_epoch, batch_size=1, callbacks=[CustomCallback()])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5463fd0",
   "metadata": {
    "papermill": {
     "duration": 0.142237,
     "end_time": "2024-11-07T19:21:03.568487",
     "exception": false,
     "start_time": "2024-11-07T19:21:03.426250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load LoRA\n",
    "\n",
    "Use the code below if you shared LoRA weights. It's much more lightweight than the model files themselves - for instance, a LoRA rank 4 weights file for a 10gb model might only be on the order of a few megabytes, easily shared over email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be007413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T19:21:03.860730Z",
     "iopub.status.busy": "2024-11-07T19:21:03.860329Z",
     "iopub.status.idle": "2024-11-07T19:21:03.867081Z",
     "shell.execute_reply": "2024-11-07T19:21:03.866259Z"
    },
    "papermill": {
     "duration": 0.158312,
     "end_time": "2024-11-07T19:21:03.869030",
     "exception": false,
     "start_time": "2024-11-07T19:21:03.710718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nimport keras\\nimport keras_nlp\\n\\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma2_instruct_2b_en\")\\n# Use the same LoRA rank that you trained\\ngemma_lm.backbone.enable_lora(rank=4)\\n\\n# Load pre-trained LoRA weights\\ngemma_lm.backbone.load_lora_weights(f\"/kaggle/working/cakeboss_4_epoch17.lora.h5\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example Code for Load LoRA\n",
    "'''\n",
    "import os\n",
    "import keras\n",
    "import keras_nlp\n",
    "\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma2_instruct_2b_en\")\n",
    "# Use the same LoRA rank that you trained\n",
    "gemma_lm.backbone.enable_lora(rank=4)\n",
    "\n",
    "# Load pre-trained LoRA weights\n",
    "gemma_lm.backbone.load_lora_weights(f\"/kaggle/working/cakeboss_4_epoch17.lora.h5\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d293df",
   "metadata": {
    "papermill": {
     "duration": 0.141114,
     "end_time": "2024-11-07T19:21:04.151154",
     "exception": false,
     "start_time": "2024-11-07T19:21:04.010040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Try a different sampler\n",
    "\n",
    "The top-K algorithm randomly picks the next token from the tokens of top K probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "272868ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T19:21:04.440064Z",
     "iopub.status.busy": "2024-11-07T19:21:04.439642Z",
     "iopub.status.idle": "2024-11-07T19:21:25.239498Z",
     "shell.execute_reply": "2024-11-07T19:21:25.238482Z"
    },
    "papermill": {
     "duration": 20.948708,
     "end_time": "2024-11-07T19:21:25.241723",
     "exception": false,
     "start_time": "2024-11-07T19:21:04.293015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "আমাকে ঢাকার একটি অবস্থান দেখান<end_of_turn>\n",
      "<start_of_turn>model\n",
      "דינהর কান্তনগরের কামারুদী মন্দিরে পাহাড়ের পাশে অবস্থিত এই জমিদার বাড়ি ঢাকার একটি প্রাচীন প্রধানমনিরওয়ার স্থাপত্যকাহিত্যমূলক বোর্ডিং।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 18.90s\n",
      "\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "পুঠিয়া রাজবাড়ী কয় তলা বিশিষ্ট?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "পুঠিয়া রাজবাড়ী তলা বিশিষ্ট ৬টি।<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.28s\n"
     ]
    }
   ],
   "source": [
    "gemma_lm.compile(sampler=\"top_k\")\n",
    "\n",
    "text_gen(\"আমাকে ঢাকার একটি অবস্থান দেখান\" )\n",
    "text_gen(\"পুঠিয়া রাজবাড়ী কয় তলা বিশিষ্ট?\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4ac832",
   "metadata": {
    "papermill": {
     "duration": 0.145781,
     "end_time": "2024-11-07T19:21:25.533243",
     "exception": false,
     "start_time": "2024-11-07T19:21:25.387462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Future work\n",
    "To improve the notebook and enhance its performance, usability, and effectiveness for fine-tuning Gemma 2 for Hindi language tasks, consider the following steps:\n",
    "\n",
    "1. Data Preprocessing and Augmentation\n",
    "\n",
    "2. Model Optimization\n",
    "\n",
    "3. Hyperparameter Tuning\n",
    "\n",
    "4. Language-Specific Enhancements\n",
    "\n",
    "5. Error Handling and Robustness\n",
    "\n",
    "6. Performance Evaluation\n",
    "\n",
    "7. Documentation and Code Clarity\n",
    "\n",
    "8. Integration with Business Applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb0723",
   "metadata": {
    "papermill": {
     "duration": 0.14333,
     "end_time": "2024-11-07T19:21:25.819975",
     "exception": false,
     "start_time": "2024-11-07T19:21:25.676645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "In conclusion, Gemma 2 can serve the medical community in correctly analysing and replying to queries on topics such as Cancer in native languages such as Hindi. Many of the patients can get clarifications with accurate answers from the fine tuned Gemma. Thus Gemma can play a vital role in providing  knowledgeble responses to millions of Hindi speakers without overwhelming the Medical facilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55358ea2",
   "metadata": {
    "papermill": {
     "duration": 0.142526,
     "end_time": "2024-11-07T19:21:26.105143",
     "exception": false,
     "start_time": "2024-11-07T19:21:25.962617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Additional References\n",
    "**Data Preprocessing and Augmentation**: Goldberg, Y. (2017). Neural Network Methods for Natural Language Processing. Morgan & Claypool Publishers.\n",
    "Sarkar, D. (2019). Text Analytics with Python: A Practical Guide to Optimizing Natural Language Processing Models. Apress.\n",
    "\n",
    "**Model Optimization**: Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.\n",
    "Vaswani, A., et al. (2017). Attention Is All You Need. arXiv preprint arXiv:1706.03762.\n",
    "\n",
    "**Hyperparameter Tuning**: Smith, L. N. (2018). A disciplined approach to neural network hyper-parameters: Part 1--learning rate, batch size, momentum, and weight decay. arXiv preprint arXiv:1803.09820.\n",
    "\n",
    "**Language-Specific Enhancements**: Ruder, S., et al. (2019). Transfer Learning in Natural Language Processing. In Proceedings of the 2019 Annual Conference of the Association for Computational Linguistics (ACL).\n",
    "\n",
    "**Error Handling**: Géron, A. (2019). Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow. O'Reilly Media, Inc.\n",
    "\n",
    "**Performance Evaluation**: Papineni, K., et al. (2002). BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.\n",
    "Lin, C.-Y. (2004). ROUGE: A Package for Automatic Evaluation of Summaries. In Proceedings of the ACL Workshop on Text Summarization.\n",
    "\n",
    "**Documentation and Code Clarity**: VanderPlas, J. (2016). Python Data Science Handbook. O'Reilly Media, Inc."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9690815,
     "sourceId": 85416,
     "sourceType": "competition"
    },
    {
     "datasetId": 5971599,
     "sourceId": 9753228,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6034122,
     "sourceId": 9836932,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6034224,
     "sourceId": 9837055,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 78150,
     "modelInstanceId": 72246,
     "sourceId": 85986,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30776,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1095.176043,
   "end_time": "2024-11-07T19:21:29.476093",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-07T19:03:14.300050",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
