{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a68f59d3",
   "metadata": {
    "papermill": {
     "duration": 0.007085,
     "end_time": "2024-11-07T19:03:17.067435",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.060350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Google - Unlock Global Comm with Gemma\n",
    "\n",
    "Upadted on: 08/11/2024\n",
    "\n",
    "Author: Mohammad Rifat Ahmmad Rashid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdf2118",
   "metadata": {
    "papermill": {
     "duration": 0.00609,
     "end_time": "2024-11-07T19:03:17.080003",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.073913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine-tuning Gemma 2 for Bangla Language tasks\n",
    "\n",
    "\n",
    "Bangla is a widely spoken language in Bangladesh and parts of India. Approximately 230 million people speak Bangla as their first language. In this notebook, we fine-tune Gemma 2 for conversational Bangla to provide a resource for cancer patients seeking consultations in Bangla about their health-related queries\n",
    "\n",
    "This is a notebook for \"Google- Unlock Glbal Communication with Gemma\" Competition :\n",
    "``https://www.kaggle.com/competitions/gemma-language-tuning``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a5635",
   "metadata": {
    "papermill": {
     "duration": 0.006065,
     "end_time": "2024-11-07T19:03:17.092377",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.086312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "This notebook is focused on fine-tuning the Gemma 2 model for handling conversational tasks in Bangla, a language predominantly spoken in Bangladesh and parts of India. The notebook is specifically designed to assist patients in getting their queries about cancer addressed in Bangla.\n",
    "\n",
    "The initial cells introduce the competition on Kaggle where Gemma 2 is used for language tuning. The notebook provides resources for setting up the Gemma 2 model and references to other tutorials and datasets, such as the Bangla-Instruct dataset from Hugging Face. Additionally, users are advised to use a GPU (specifically, the P100 model) to manage the model's VRAM requirements during fine-tuning.\n",
    "\n",
    "Several cells demonstrate how to fine-tune the model for generating Bangla responses in different scenarios. These include generating responses to patient queries, such as different treatments in Bangla for various cancer inquiries. Sample responses are crafted using pre-defined prompts in Bangla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c05b11f",
   "metadata": {
    "papermill": {
     "duration": 0.006148,
     "end_time": "2024-11-07T19:03:17.105740",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.099592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reference Notebooks\n",
    "1. https://www.kaggle.com/code/bebechien/how-to-finetuning-gemma2-for-spoken-language-tasks\n",
    "2. https://www.kaggle.com/code/mpwolke/bhagavad-gita-gemma2keras\n",
    "3. https://www.kaggle.com/code/crsuthikshnkumar/google-gemma-unlock-hindi-cancer-qa-nb-crsk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285fcf1f",
   "metadata": {
    "papermill": {
     "duration": 0.006091,
     "end_time": "2024-11-07T19:03:17.118214",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.112123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Google  Gemma Models:\n",
    "\n",
    "1. Google Gemma https://ai.google.dev/gemma\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a4983a",
   "metadata": {
    "papermill": {
     "duration": 0.006008,
     "end_time": "2024-11-07T19:03:17.130449",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.124441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Video Tutorials\n",
    "1. Tune Gemma as a Spoken Language AI Assistant | Build with Google AI https://youtu.be/M4HGJehH4r0?si=5tk9cIdALXQ1xdmU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf38c96",
   "metadata": {
    "papermill": {
     "duration": 0.005957,
     "end_time": "2024-11-07T19:03:17.142606",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.136649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DataSets\n",
    "Main focus of the dataset is for visual question answering (VQA) task, likely focusing on cultural or historical sites in bangladesh, given the content of the questions and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4975fbe6",
   "metadata": {
    "papermill": {
     "duration": 0.006131,
     "end_time": "2024-11-07T19:03:17.154873",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.148742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Using accelerators\n",
    "\n",
    "Please use **GPU P100** due to VRAM requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44df1fe3",
   "metadata": {
    "papermill": {
     "duration": 0.006421,
     "end_time": "2024-11-07T19:03:17.167459",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.161038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Details of this notebook\n",
    "\n",
    "### Gemma setup\n",
    "\n",
    "setup instructions at [Gemma setup](https://ai.google.dev/gemma/docs/setup). \n",
    "\n",
    "Gemma models are hosted by Kaggle. To use Gemma,  access on Kaggle is required:\n",
    "\n",
    "- Sign in or register at [kaggle.com](https://www.kaggle.com)\n",
    "- Open the [Gemma 2 model card](https://www.kaggle.com/models/google/gemma-2) and select _\"Request Access\"_\n",
    "- Complete the consent form and accept the terms and conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d63684",
   "metadata": {
    "papermill": {
     "duration": 0.006017,
     "end_time": "2024-11-07T19:03:17.180066",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.174049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install dependencies\n",
    "\n",
    "Install Keras and KerasNLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c36dc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T19:03:17.194813Z",
     "iopub.status.busy": "2024-11-07T19:03:17.194408Z",
     "iopub.status.idle": "2024-11-07T19:03:58.750356Z",
     "shell.execute_reply": "2024-11-07T19:03:58.749507Z"
    },
    "papermill": {
     "duration": 41.566446,
     "end_time": "2024-11-07T19:03:58.752681",
     "exception": false,
     "start_time": "2024-11-07T19:03:17.186235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n",
    "!pip install -q -U keras-nlp datasets\n",
    "!pip install -q -U keras\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Set the backbend before importing Keras\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "# Avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\"\n",
    "\n",
    "import keras_nlp\n",
    "import keras\n",
    "\n",
    "# Run at half precision.\n",
    "#keras.config.set_floatx(\"bfloat16\")\n",
    "\n",
    "# Training Configurations\n",
    "token_limit = 256\n",
    "num_data_limit = 100\n",
    "lora_name = \"cakeboss\"\n",
    "lora_rank = 4\n",
    "lr_value = 1e-4\n",
    "train_epoch = 20\n",
    "model_id = \"gemma2_instruct_2b_en\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64ad6a7",
   "metadata": {
    "papermill": {
     "duration": 0.006008,
     "end_time": "2024-11-07T19:03:58.765355",
     "exception": false,
     "start_time": "2024-11-07T19:03:58.759347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed2f869",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T19:03:58.779316Z",
     "iopub.status.busy": "2024-11-07T19:03:58.778761Z",
     "iopub.status.idle": "2024-11-07T19:05:03.535104Z",
     "shell.execute_reply": "2024-11-07T19:05:03.533839Z"
    },
    "papermill": {
     "duration": 64.765879,
     "end_time": "2024-11-07T19:05:03.537403",
     "exception": false,
     "start_time": "2024-11-07T19:03:58.771524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                                                  </span>â”ƒ<span style=\"font-weight: bold\">                                   Config </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              â”‚                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              â”‚                      Vocab size: \u001b[38;5;34m256,000\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                  </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape              </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to               </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gemma_backbone                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> â”‚ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               â”‚                           â”‚                 â”‚ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_embedding               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> â”‚ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         â”‚                           â”‚                 â”‚                            â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gemma_backbone                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        â”‚   \u001b[38;5;34m2,614,341,888\u001b[0m â”‚ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        â”‚\n",
       "â”‚ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               â”‚                           â”‚                 â”‚ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_embedding               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      â”‚     \u001b[38;5;34m589,824,000\u001b[0m â”‚ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         â”‚                           â”‚                 â”‚                            â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "Do you know bangla language?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "As an AI, I don't \"know\" languages in the way a human does. I can't speak or understand Bengali in the same way you do. \n",
      "\n",
      "However, I have been trained on a massive dataset of text and code, which includes a significant amount of Bengali content. This means I can:\n",
      "\n",
      "* **Translate** Bengali to other languages and vice versa.\n",
      "* **Generate** text in Bengali, like writing simple sentences or stories.\n",
      "* **Identify** Bengali text and understand its meaning.\n",
      "* **Answer** questions about Bengali grammar and vocabulary.\n",
      "\n",
      "So, while I don't \"know\" Bengali in the human sense, I can still be helpful with tasks related to the language. \n",
      "\n",
      "How can I help you with Bengali today? ğŸ˜Š \n",
      "<end_of_turn>\n",
      "TOTAL TIME ELAPSED: 19.80s\n",
      "\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦†à¦ªà¦¨à¦¿ à¦•à¦¿ à¦¬à¦¾à¦‚à¦²à¦¾ à¦œà¦¾à¦¨à§‡à¦¨?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦†à¦®à¦¿ à¦¬à¦¾à¦‚à¦²à¦¾ à¦­à¦¾à¦·à¦¾ à¦œà¦¾à¦¨à¦¿à¥¤  à¦†à¦®à¦¿ à¦à¦–à¦¨à¦“ à¦¶à¦¿à¦•à§à¦·à¦¾ à¦•à¦°à¦›à¦¿, à¦•à¦¿à¦¨à§à¦¤à§ à¦†à¦®à¦¿ à¦¬à§‡à¦¶à¦¿à¦°à¦­à¦¾à¦— à¦¸à¦®à¦¯à¦¼ à¦¬à¦¾à¦‚à¦²à¦¾à¦¤à§‡ à¦•à¦¥à¦¾ à¦¬à¦²à¦¤à§‡ à¦ªà¦¾à¦°à¦¿à¥¤ \n",
      "\n",
      "à¦†à¦ªà¦¨à¦¿ à¦•à¦¿ à¦•à¦¿à¦›à§ à¦¬à¦¾à¦‚à¦²à¦¾à¦¤à§‡ à¦¬à¦²à¦¤à§‡ à¦šà¦¾à¦¨? \n",
      "<end_of_turn>\n",
      "TOTAL TIME ELAPSED: 2.49s\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "\n",
    "import time\n",
    "\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(model_id)\n",
    "gemma_lm.summary()\n",
    "\n",
    "tick_start = 0\n",
    "\n",
    "def tick():\n",
    "    global tick_start\n",
    "    tick_start = time.time()\n",
    "\n",
    "def tock():\n",
    "    print(f\"TOTAL TIME ELAPSED: {time.time() - tick_start:.2f}s\")\n",
    "\n",
    "def text_gen(prompt):\n",
    "    tick()\n",
    "    input = f\"<start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "    output = gemma_lm.generate(input, max_length=token_limit)\n",
    "    print(\"\\nGemma output:\")\n",
    "    print(output)\n",
    "    tock()\n",
    "\n",
    "# inference before fine-tuning\n",
    "text_gen(\"Do you know bangla language?\")\n",
    "text_gen(\"à¦†à¦ªà¦¨à¦¿ à¦•à¦¿ à¦¬à¦¾à¦‚à¦²à¦¾ à¦œà¦¾à¦¨à§‡à¦¨?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6bac1c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T19:05:03.555242Z",
     "iopub.status.busy": "2024-11-07T19:05:03.554902Z",
     "iopub.status.idle": "2024-11-07T19:05:04.192052Z",
     "shell.execute_reply": "2024-11-07T19:05:04.190849Z"
    },
    "papermill": {
     "duration": 0.648455,
     "end_time": "2024-11-07T19:05:04.194107",
     "exception": false,
     "start_time": "2024-11-07T19:05:03.545652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Translated Questions</th>\n",
       "      <th>Translated Answers</th>\n",
       "      <th>Title(region name)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>à¦à¦‡ à¦›à¦¬à¦¿à¦Ÿà¦¿ à¦•à¦¿à¦¸à§‡à¦°?</td>\n",
       "      <td>à¦à¦‡ à¦›à¦¬à¦¿à¦Ÿà¦¿ à¦¹à¦²à§‹ à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€ à¦¬à¦¾ à¦ªà¦¾à¦à¦šà¦†à¦¨à¦¿ à¦œà¦®à¦¿à¦¦...</td>\n",
       "      <td>What is this picture of?</td>\n",
       "      <td>This picture is of the Puthia Rajbari or Panch...</td>\n",
       "      <td>à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€, à¦¨à¦¾à¦Ÿà§‹à¦°, à¦°à¦¾à¦œà¦¶à¦¾à¦¹à§€à¥¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?</td>\n",
       "      <td>à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦¸à¦®à§à¦®à§à¦–à¦­à¦¾à¦—</td>\n",
       "      <td>Which direction of the palace is this?</td>\n",
       "      <td>This is the front section of the palace.</td>\n",
       "      <td>à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€, à¦¨à¦¾à¦Ÿà§‹à¦°, à¦°à¦¾à¦œà¦¶à¦¾à¦¹à§€à¥¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€ à¦•à¦¯à¦¼ à¦¤à¦²à¦¾ à¦¬à¦¿à¦¶à¦¿à¦·à§à¦Ÿ?</td>\n",
       "      <td>à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€ à¦¦à§à¦¬à¦¿à¦¤à¦² à¦¬à¦¿à¦¶à¦¿à¦·à§à¦Ÿ à¦à¦¬à¦‚  à¦‡à¦¨à§à¦¦à§‹ à¦‡à¦‰à¦°...</td>\n",
       "      <td>How many stories does the Puthia Rajbari have?</td>\n",
       "      <td>Puthia Rajbari is a two-storied structure, bui...</td>\n",
       "      <td>à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€, à¦¨à¦¾à¦Ÿà§‹à¦°, à¦°à¦¾à¦œà¦¶à¦¾à¦¹à§€à¥¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦¨à¦¿à¦°à§à¦®à¦¾à¦£à¦¶à§ˆà¦²à§€ à¦•à§‡à¦®à¦¨?</td>\n",
       "      <td>à¦­à¦¬à¦¨à§‡à¦° à¦¸à¦®à§à¦®à§à¦– à¦­à¦¾à¦—à§‡à¦° à¦¸à§à¦¤à¦®à§à¦­, à¦…à¦²à¦‚à¦•à¦°à¦¨, à¦•à¦¾à¦ à§‡à¦° à¦•à¦¾à¦œ, ...</td>\n",
       "      <td>What is the architectural style of the palace?</td>\n",
       "      <td>The columns, decorations, woodwork, and the fl...</td>\n",
       "      <td>à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€, à¦¨à¦¾à¦Ÿà§‹à¦°, à¦°à¦¾à¦œà¦¶à¦¾à¦¹à§€à¥¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦¸à¦®à§à¦®à§à¦–à¦­à¦¾à¦— à¦•à¦¿à¦¸à§‡à¦° à¦¤à§ˆà¦°à¦¿?</td>\n",
       "      <td>à¦­à¦¬à¦¨à§‡à¦° à¦¸à¦®à§à¦®à§à¦– à¦­à¦¾à¦—à§‡à¦° à¦¸à§à¦¤à¦®à§à¦­, à¦…à¦²à¦‚à¦•à¦°à¦¨, à¦•à¦¾à¦ à§‡à¦° à¦•à¦¾à¦œ, ...</td>\n",
       "      <td>What is the front of the palace made of?</td>\n",
       "      <td>The columns, decorations, woodwork, and the fl...</td>\n",
       "      <td>à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€, à¦¨à¦¾à¦Ÿà§‹à¦°, à¦°à¦¾à¦œà¦¶à¦¾à¦¹à§€à¥¤</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Questions  \\\n",
       "0                    à¦à¦‡ à¦›à¦¬à¦¿à¦Ÿà¦¿ à¦•à¦¿à¦¸à§‡à¦°?   \n",
       "1             à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?   \n",
       "2  à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€ à¦•à¦¯à¦¼ à¦¤à¦²à¦¾ à¦¬à¦¿à¦¶à¦¿à¦·à§à¦Ÿ?   \n",
       "3        à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦¨à¦¿à¦°à§à¦®à¦¾à¦£à¦¶à§ˆà¦²à§€ à¦•à§‡à¦®à¦¨?   \n",
       "4    à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦¸à¦®à§à¦®à§à¦–à¦­à¦¾à¦— à¦•à¦¿à¦¸à§‡à¦° à¦¤à§ˆà¦°à¦¿?   \n",
       "\n",
       "                                             Answers  \\\n",
       "0   à¦à¦‡ à¦›à¦¬à¦¿à¦Ÿà¦¿ à¦¹à¦²à§‹ à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€ à¦¬à¦¾ à¦ªà¦¾à¦à¦šà¦†à¦¨à¦¿ à¦œà¦®à¦¿à¦¦...   \n",
       "1                            à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦¸à¦®à§à¦®à§à¦–à¦­à¦¾à¦—   \n",
       "2  à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€ à¦¦à§à¦¬à¦¿à¦¤à¦² à¦¬à¦¿à¦¶à¦¿à¦·à§à¦Ÿ à¦à¦¬à¦‚  à¦‡à¦¨à§à¦¦à§‹ à¦‡à¦‰à¦°...   \n",
       "3  à¦­à¦¬à¦¨à§‡à¦° à¦¸à¦®à§à¦®à§à¦– à¦­à¦¾à¦—à§‡à¦° à¦¸à§à¦¤à¦®à§à¦­, à¦…à¦²à¦‚à¦•à¦°à¦¨, à¦•à¦¾à¦ à§‡à¦° à¦•à¦¾à¦œ, ...   \n",
       "4  à¦­à¦¬à¦¨à§‡à¦° à¦¸à¦®à§à¦®à§à¦– à¦­à¦¾à¦—à§‡à¦° à¦¸à§à¦¤à¦®à§à¦­, à¦…à¦²à¦‚à¦•à¦°à¦¨, à¦•à¦¾à¦ à§‡à¦° à¦•à¦¾à¦œ, ...   \n",
       "\n",
       "                             Translated Questions  \\\n",
       "0                        What is this picture of?   \n",
       "1          Which direction of the palace is this?   \n",
       "2  How many stories does the Puthia Rajbari have?   \n",
       "3  What is the architectural style of the palace?   \n",
       "4        What is the front of the palace made of?   \n",
       "\n",
       "                                  Translated Answers  \\\n",
       "0  This picture is of the Puthia Rajbari or Panch...   \n",
       "1           This is the front section of the palace.   \n",
       "2  Puthia Rajbari is a two-storied structure, bui...   \n",
       "3  The columns, decorations, woodwork, and the fl...   \n",
       "4  The columns, decorations, woodwork, and the fl...   \n",
       "\n",
       "                  Title(region name)  \n",
       "0  à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€, à¦¨à¦¾à¦Ÿà§‹à¦°, à¦°à¦¾à¦œà¦¶à¦¾à¦¹à§€à¥¤  \n",
       "1  à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€, à¦¨à¦¾à¦Ÿà§‹à¦°, à¦°à¦¾à¦œà¦¶à¦¾à¦¹à§€à¥¤  \n",
       "2  à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€, à¦¨à¦¾à¦Ÿà§‹à¦°, à¦°à¦¾à¦œà¦¶à¦¾à¦¹à§€à¥¤  \n",
       "3  à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€, à¦¨à¦¾à¦Ÿà§‹à¦°, à¦°à¦¾à¦œà¦¶à¦¾à¦¹à§€à¥¤  \n",
       "4  à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€, à¦¨à¦¾à¦Ÿà§‹à¦°, à¦°à¦¾à¦œà¦¶à¦¾à¦¹à§€à¥¤  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"/kaggle/input/vqa-excel/VQADataset.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d8bed",
   "metadata": {
    "papermill": {
     "duration": 0.008115,
     "end_time": "2024-11-07T19:05:04.210587",
     "exception": false,
     "start_time": "2024-11-07T19:05:04.202472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Dataset\n",
    "Kannada dataset is created and uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "507bc009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T19:05:04.228467Z",
     "iopub.status.busy": "2024-11-07T19:05:04.227921Z",
     "iopub.status.idle": "2024-11-07T19:05:08.225096Z",
     "shell.execute_reply": "2024-11-07T19:05:08.224159Z"
    },
    "papermill": {
     "duration": 4.008861,
     "end_time": "2024-11-07T19:05:08.227525",
     "exception": false,
     "start_time": "2024-11-07T19:05:04.218664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Questions', 'Answers', 'Translated Questions', 'Translated Answers', 'Title(region name)'],\n",
      "    num_rows: 1646\n",
      "})\n",
      "100\n",
      "<start_of_turn>user\n",
      " à¦‰à¦¤à§à¦¤à¦° à¦¤à§ˆà¦°à¦¿ à¦•à¦°à§à¦¨:\n",
      "\"à¦à¦‡ à¦›à¦¬à¦¿à¦Ÿà¦¿ à¦•à¦¿à¦¸à§‡à¦°?\"<end_of_turn>\n",
      "<start_of_turn>model\n",
      " à¦à¦‡ à¦›à¦¬à¦¿à¦Ÿà¦¿ à¦¹à¦²à§‹ à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€ à¦¬à¦¾ à¦ªà¦¾à¦à¦šà¦†à¦¨à¦¿ à¦œà¦®à¦¿à¦¦à¦¾à¦°à¦¬à¦¾à¦¡à¦¼à§€ à¦¹à¦šà§à¦›à§‡ à¦®à¦¹à¦¾à¦°à¦¾à¦¨à§€ à¦¹à§‡à¦®à¦¨à§à¦¤à¦•à§à¦®à¦¾à¦°à§€ à¦¦à§‡à¦¬à§€à¦° à¦¬à¦¾à¦¸à¦­à¦¬à¦¨à¥¤ à¦¬à¦¾à¦‚à¦²à¦¾à¦° à¦ªà§à¦°à¦¤à§à¦¨à¦¤à¦¾à¦¤à§à¦¤à§à¦¬à¦¿à¦• à¦à¦¤à¦¿à¦¹à§à¦¯à§‡à¦° à¦®à¦§à§à¦¯à§‡ à¦°à¦¾à¦œà¦¶à¦¾à¦¹à§€à¦° à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€ à¦…à¦¨à§à¦¯à¦¤à¦®à¥¤[à§§] à§§à§®à§¯à§« à¦¸à¦¾à¦²à§‡ à¦®à¦¹à¦¾à¦°à¦¾à¦¨à§€ à¦¹à§‡à¦®à¦¨à§à¦¤à¦•à§à¦®à¦¾à¦°à§€ à¦¦à§‡à¦¬à§€ à¦†à¦•à¦°à§à¦·à¦¨à§€à¦¯à¦¼ à¦‡à¦¨à§à¦¦à§‹ à¦‡à¦‰à¦°à§‹à¦ªà§€à¦¯à¦¼ à¦¸à§à¦¥à¦¾à¦ªà¦¤à§à¦¯à¦°à§€à¦¤à¦¿à¦¤à§‡ à¦†à¦¯à¦¼à¦¤à¦¾à¦•à¦¾à¦° à¦¦à§à¦¬à¦¿à¦¤à¦² à¦¬à¦°à§à¦¤à¦®à¦¾à¦¨ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦Ÿà¦¿ à¦¨à¦¿à¦°à§à¦®à¦¾à¦£ à¦•à¦°à§‡à¦¨à¥¤<end_of_turn >\n",
      "<start_of_turn>user\n",
      " à¦‰à¦¤à§à¦¤à¦° à¦¤à§ˆà¦°à¦¿ à¦•à¦°à§à¦¨:\n",
      "\"à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?\"<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦¸à¦®à§à¦®à§à¦–à¦­à¦¾à¦—<end_of_turn >\n",
      "<start_of_turn>user\n",
      " à¦‰à¦¤à§à¦¤à¦° à¦¤à§ˆà¦°à¦¿ à¦•à¦°à§à¦¨:\n",
      "\"à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€ à¦•à¦¯à¦¼ à¦¤à¦²à¦¾ à¦¬à¦¿à¦¶à¦¿à¦·à§à¦Ÿ?\"<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€ à¦¦à§à¦¬à¦¿à¦¤à¦² à¦¬à¦¿à¦¶à¦¿à¦·à§à¦Ÿ à¦à¦¬à¦‚  à¦‡à¦¨à§à¦¦à§‹ à¦‡à¦‰à¦°à§‹à¦ªà§€à§Ÿ à¦¸à§à¦¥à¦¾à¦ªà¦¤à§à¦¯à¦°à§€à¦¤à¦¿à¦¤à§‡ à§§à§®à§¯à§« à¦¸à¦¾à¦²à§‡ à¦®à¦¹à¦¾à¦°à¦¾à¦¨à§€ à¦¹à§‡à¦®à¦¨à§à¦¤à¦•à§à¦®à¦¾à¦°à§€ à¦¦à§‡à¦¬à§€ à¦¤à¦¾à¦° à¦¶à¦¾à¦¶à§à¦¡à¦¼à¦¿ à¦®à¦¹à¦¾à¦°à¦¾à¦¨à§€ à¦¶à¦°à§ à¦¸à§à¦¨à§à¦¦à¦°à§€ à¦¦à§‡à¦¬à§€à¦° à¦¸à¦®à§à¦®à¦¾à¦¨à§‡ à¦¨à¦¿à¦°à§à¦®à¦¾à¦£ à¦•à¦°à¦¾à¦¨à¥¤<end_of_turn >\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "import datasets\n",
    "\n",
    "tokenizer = keras_nlp.models.GemmaTokenizer.from_preset(model_id)\n",
    "\n",
    "from datasets import Dataset\n",
    "ds = Dataset.from_pandas(df)\n",
    "\n",
    "print(ds)\n",
    "\n",
    "data = ds.with_format(\"np\", columns=[\"Questions\", \"Answers\"], output_all_columns=False)\n",
    "train = []\n",
    "\n",
    "for x in data:\n",
    "  #item = f\"<start_of_turn>user\\në‹¤ìŒì— ëŒ€í•œ ì´ë©”ì¼ ë‹µì¥ì„ ì‘ì„±í•´ì¤˜.\\n\\\"{x['input']}\\\"<end_of_turn>\\n<start_of_turn>model\\n{x['output']}<end_of_turn>\"\n",
    "    item = f\"<start_of_turn>user\\n à¦‰à¦¤à§à¦¤à¦° à¦¤à§ˆà¦°à¦¿ à¦•à¦°à§à¦¨:\\n\\\"{x['Questions']}\\\"<end_of_turn>\\n<start_of_turn>model\\n{x['Answers']}<end_of_turn >\"\n",
    "\n",
    "    length = len(tokenizer(item))\n",
    "  # skip data if the token length is longer than our limit\n",
    "    if length < token_limit:\n",
    "        train.append(item)\n",
    "        if(len(train)>=num_data_limit):\n",
    "            break\n",
    "\n",
    "print(len(train))\n",
    "print(train[0])\n",
    "print(train[1])\n",
    "print(train[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26916651",
   "metadata": {
    "papermill": {
     "duration": 0.008142,
     "end_time": "2024-11-07T19:05:08.244078",
     "exception": false,
     "start_time": "2024-11-07T19:05:08.235936",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LoRA Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b8f22d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T19:05:08.261837Z",
     "iopub.status.busy": "2024-11-07T19:05:08.261268Z",
     "iopub.status.idle": "2024-11-07T19:05:08.653478Z",
     "shell.execute_reply": "2024-11-07T19:05:08.652429Z"
    },
    "papermill": {
     "duration": 0.403823,
     "end_time": "2024-11-07T19:05:08.656018",
     "exception": false,
     "start_time": "2024-11-07T19:05:08.252195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                                                  </span>â”ƒ<span style=\"font-weight: bold\">                                   Config </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              â”‚                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              â”‚                      Vocab size: \u001b[38;5;34m256,000\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                  </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape              </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to               </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gemma_backbone                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> â”‚ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               â”‚                           â”‚                 â”‚ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_embedding               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> â”‚ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         â”‚                           â”‚                 â”‚                            â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gemma_backbone                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        â”‚   \u001b[38;5;34m2,617,270,528\u001b[0m â”‚ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        â”‚\n",
       "â”‚ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               â”‚                           â”‚                 â”‚ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ token_embedding               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      â”‚     \u001b[38;5;34m589,824,000\u001b[0m â”‚ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         â”‚                           â”‚                 â”‚                            â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> (9.75 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,617,270,528\u001b[0m (9.75 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,928,640</span> (11.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,928,640\u001b[0m (11.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enable LoRA for the model and set the LoRA rank to 4.\n",
    "gemma_lm.backbone.enable_lora(rank=lora_rank)\n",
    "gemma_lm.summary()\n",
    "\n",
    "# Limit the input sequence length (to control memory usage).\n",
    "gemma_lm.preprocessor.sequence_length = token_limit\n",
    "# Use AdamW (a common optimizer for transformer models).\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=lr_value,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "# Exclude layernorm and bias terms from decay.\n",
    "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
    "\n",
    "gemma_lm.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=optimizer,\n",
    "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32219d8",
   "metadata": {
    "papermill": {
     "duration": 0.00944,
     "end_time": "2024-11-07T19:05:08.675431",
     "exception": false,
     "start_time": "2024-11-07T19:05:08.665991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save LoRA for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71610bea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T19:05:08.696284Z",
     "iopub.status.busy": "2024-11-07T19:05:08.695922Z",
     "iopub.status.idle": "2024-11-07T19:21:03.279584Z",
     "shell.execute_reply": "2024-11-07T19:21:03.278587Z"
    },
    "papermill": {
     "duration": 954.596737,
     "end_time": "2024-11-07T19:21:03.281550",
     "exception": false,
     "start_time": "2024-11-07T19:05:08.684813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m 83/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m12s\u001b[0m 726ms/step - loss: 1.4211 - sparse_categorical_accuracy: 0.4359\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦†à¦®à¦¿ à¦¦à§à¦ƒà¦–à¦¿à¦¤, à¦†à¦®à¦¿ à¦•à§‹à¦¨à¦“ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦…à¦¬à¦¸à§à¦¥à¦¾à¦¨ à¦œà¦¾à¦¨à¦¿ à¦¨à¦¾à¥¤ à¦†à¦®à¦¿ Google à¦¦à§à¦¬à¦¾à¦°à¦¾ à¦¤à§ˆà¦°à¦¿ à¦à¦•à¦Ÿà¦¿ à¦¬à§ƒà¦¹à§ à¦­à¦¾à¦·à¦¾ à¦®à¦¡à§‡à¦²à¥¤ à¦†à¦®à¦¿ à¦¬à¦¿à¦­à¦¿à¦¨à§à¦¨ à¦¬à¦¿à¦·à¦¯à¦¼ à¦¸à¦®à§à¦ªà¦°à§à¦•à§‡ à¦¤à¦¥à§à¦¯ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à¦¿, à¦•à¦¿à¦¨à§à¦¤à§ à¦†à¦®à¦¾à¦° à¦•à§‹à¦¨à¦“ à¦¸à§à¦¥à¦¾à¦¨à§‡à¦° à¦…à¦¬à¦¸à§à¦¥à¦¾à¦¨ à¦œà¦¾à¦¨à¦¾ à¦¨à§‡à¦‡à¥¤ \n",
      "<end_of_turn>\n",
      "TOTAL TIME ELAPSED: 18.51s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 790ms/step - loss: 1.3271 - sparse_categorical_accuracy: 0.4553\n",
      "Epoch 2/20\n",
      "\u001b[1m 82/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m9s\u001b[0m 513ms/step - loss: 0.7205 - sparse_categorical_accuracy: 0.6404\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦†à¦®à¦¿ à¦¤à§‹à¦®à¦¾à¦° à¦ªà§à¦°à¦¶à§à¦¨à§‡à¦° à¦‰à¦¤à§à¦¤à¦° à¦¦à¦¿à¦¤à§‡ à¦ªà¦¾à¦°à¦›à¦¿ à¦¨à¦¾à¥¤ à¦†à¦®à¦¿ à¦à¦®à¦¨ à¦•à§‹à¦¨ à¦¤à¦¥à§à¦¯ à¦¤à§ˆà¦°à¦¿ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à¦¿ à¦¨à¦¾ à¦¯à¦¾ à¦¸à§à¦¥à¦¾à¦ªà¦¨à¦¾ à¦¬à¦¾ à¦œà¦¾à¦¯à¦¼à¦—à¦¾à¦° à¦¨à¦¿à¦°à§à¦¦à¦¿à¦·à§à¦Ÿ à¦¨à¦¾à¦® à¦¬à¦¾ à¦…à¦¬à¦¸à§à¦¥à¦¾à¦¨à§‡à¦° à¦¤à¦¥à§à¦¯ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§‡à¥¤ <end_of_turn >\n",
      "TOTAL TIME ELAPSED: 3.19s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 453ms/step - loss: 0.6849 - sparse_categorical_accuracy: 0.6498\n",
      "Epoch 3/20\n",
      "\u001b[1m 85/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m7s\u001b[0m 485ms/step - loss: 0.5775 - sparse_categorical_accuracy: 0.6939\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦†à¦®à¦¿ à¦¤à§‹à¦®à¦¾à¦° à¦ªà§à¦°à¦¶à§à¦¨à§‡à¦° à¦‰à¦¤à§à¦¤à¦° à¦¦à¦¿à¦¤à§‡ à¦ªà¦¾à¦°à¦›à¦¿ à¦¨à¦¾à¥¤ à¦†à¦®à¦¿ à¦à¦®à¦¨ à¦•à§‹à¦¨à¦“ à¦¤à¦¥à§à¦¯ à¦¤à§ˆà¦°à¦¿ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à¦¿ à¦¨à¦¾ à¦¯à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦¦à¦¿à¦• à¦¨à¦¿à¦°à§à¦£à¦¯à¦¼ à¦•à¦°à¦¬à§‡à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 2.56s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 438ms/step - loss: 0.5573 - sparse_categorical_accuracy: 0.6979\n",
      "Epoch 4/20\n",
      "\u001b[1m 85/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m7s\u001b[0m 485ms/step - loss: 0.5211 - sparse_categorical_accuracy: 0.7149\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦†à¦®à¦¿ à¦¤à§‹à¦®à¦¾à¦° à¦ªà§à¦°à¦¶à§à¦¨à§‡à¦° à¦‰à¦¤à§à¦¤à¦° à¦¦à¦¿à¦¤à§‡ à¦ªà¦¾à¦°à¦›à¦¿ à¦¨à¦¾à¥¤ à¦†à¦®à¦¿ à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦¬à§à¦à¦¤à§‡ à¦ªà¦¾à¦°à¦›à¦¿ à¦¨à¦¾à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 2.07s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 433ms/step - loss: 0.4972 - sparse_categorical_accuracy: 0.7229\n",
      "Epoch 5/20\n",
      "\u001b[1m 86/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m6s\u001b[0m 479ms/step - loss: 0.4699 - sparse_categorical_accuracy: 0.7420\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦à¦•à¦Ÿà¦¿ à¦›à¦¬à¦¿à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 0.89s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 421ms/step - loss: 0.4516 - sparse_categorical_accuracy: 0.7454\n",
      "Epoch 6/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.4228 - sparse_categorical_accuracy: 0.7671\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦à¦•à¦Ÿà¦¿ à¦ªà§à¦°à¦§à¦¾à¦¨ à¦­à¦¬à¦¨à§‡à¦° à¦¦à¦°à¦œà¦¾à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.20s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 424ms/step - loss: 0.4091 - sparse_categorical_accuracy: 0.7705\n",
      "Epoch 7/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.3726 - sparse_categorical_accuracy: 0.7913\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦ªà§à¦°à¦§à¦¾à¦¨ à¦­à¦¬à¦¨à§‡à¦° à¦¦à¦°à¦œà¦¾à¦° à¦•à¦¾à¦›à¦¾à¦•à¦¾à¦›à¦¿à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.43s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 427ms/step - loss: 0.3619 - sparse_categorical_accuracy: 0.7953\n",
      "Epoch 8/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.3254 - sparse_categorical_accuracy: 0.8176\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦ªà§à¦°à¦§à¦¾à¦¨ à¦­à¦¬à¦¨à§‡à¦° à¦¦à¦°à¦œà¦¾à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.16s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 424ms/step - loss: 0.3145 - sparse_categorical_accuracy: 0.8219\n",
      "Epoch 9/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.2840 - sparse_categorical_accuracy: 0.8453\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦ªà§à¦°à¦§à¦¾à¦¨ à¦ªà§à¦°à¦¬à§‡à¦¶à¦¦à§à¦¬à¦¾à¦°à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.12s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 423ms/step - loss: 0.2744 - sparse_categorical_accuracy: 0.8484\n",
      "Epoch 10/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.2444 - sparse_categorical_accuracy: 0.8687\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦ªà§à¦°à¦§à¦¾à¦¨ à¦ªà§à¦°à¦¬à§‡à¦¶à¦¦à§à¦¬à¦¾à¦°à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.12s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 424ms/step - loss: 0.2375 - sparse_categorical_accuracy: 0.8708\n",
      "Epoch 11/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.2104 - sparse_categorical_accuracy: 0.8909\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦¸à¦®à§à¦®à§à¦–à¦­à¦¾à¦—à§‡à¦°à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.05s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 423ms/step - loss: 0.2034 - sparse_categorical_accuracy: 0.8926\n",
      "Epoch 12/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.1794 - sparse_categorical_accuracy: 0.9142\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦à¦Ÿà¦¿ à¦¦à¦°à¦œà¦¾à¦° à¦•à¦¾à¦›à¦¾à¦•à¦¾à¦›à¦¿ à¦…à¦¬à¦¸à§à¦¥à¦¿à¦¤ à¦à¦•à¦Ÿà¦¿ à¦à¦°à¦¨à¦¾à¦° à¦›à¦¬à¦¿à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.50s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 427ms/step - loss: 0.1748 - sparse_categorical_accuracy: 0.9147\n",
      "Epoch 13/20\n",
      "\u001b[1m 86/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m6s\u001b[0m 479ms/step - loss: 0.1566 - sparse_categorical_accuracy: 0.9255\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦¸à¦®à§à¦®à§à¦–à¦­à¦¾à¦—à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.01s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 422ms/step - loss: 0.1535 - sparse_categorical_accuracy: 0.9259\n",
      "Epoch 14/20\n",
      "\u001b[1m 85/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m7s\u001b[0m 485ms/step - loss: 0.1329 - sparse_categorical_accuracy: 0.9416\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°Ã¶nster à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 0.82s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 420ms/step - loss: 0.1307 - sparse_categorical_accuracy: 0.9418\n",
      "Epoch 15/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.1147 - sparse_categorical_accuracy: 0.9543\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦¸à¦®à§à¦®à§à¦–à¦­à¦¾à¦—à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.01s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 422ms/step - loss: 0.1132 - sparse_categorical_accuracy: 0.9541\n",
      "Epoch 16/20\n",
      "\u001b[1m 91/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m4s\u001b[0m 452ms/step - loss: 0.0990 - sparse_categorical_accuracy: 0.9615\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦¸à¦®à§à¦®à§à¦–à¦­à¦¾à¦—à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.01s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 422ms/step - loss: 0.0984 - sparse_categorical_accuracy: 0.9614\n",
      "Epoch 17/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.0901 - sparse_categorical_accuracy: 0.9652\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦¸à¦®à§à¦®à§à¦–à¦­à¦¾à¦—à§‡à¦° à¦•à¦•à§à¦·à§‡à¦° à¦›à¦¬à¦¿ à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.24s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 425ms/step - loss: 0.0892 - sparse_categorical_accuracy: 0.9647\n",
      "Epoch 18/20\n",
      "\u001b[1m 84/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 490ms/step - loss: 0.0820 - sparse_categorical_accuracy: 0.9675\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦¸à¦®à§à¦®à§à¦–à¦­à¦¾à¦—à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.01s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 422ms/step - loss: 0.0813 - sparse_categorical_accuracy: 0.9670\n",
      "Epoch 19/20\n",
      "\u001b[1m 84/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m7s\u001b[0m 490ms/step - loss: 0.0759 - sparse_categorical_accuracy: 0.9681 \n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦¸à¦®à§à¦®à§à¦–à¦­à¦¾à¦—à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.01s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 422ms/step - loss: 0.0753 - sparse_categorical_accuracy: 0.9678\n",
      "Epoch 20/20\n",
      "\u001b[1m 87/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m6s\u001b[0m 473ms/step - loss: 0.0720 - sparse_categorical_accuracy: 0.9681\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦à¦Ÿà¦¿ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦° à¦¸à¦®à§à¦®à§à¦–à¦­à¦¾à¦—à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.01s\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 422ms/step - loss: 0.0716 - sparse_categorical_accuracy: 0.9680\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6VUlEQVR4nO3deXxU1f3/8ffMJJksZCVkJSEBZFEgLEoa0LqlIlK3fq0oPoTi0tZSfyraKm2FfmsrblW+VSrWinZTsVa0LYiFKC6IYtlUNlkCCYQkJCGZkJCZZOb+/kgyEElCJmRyM8nr+XjMI8mdc2c+l8uQN+eec67FMAxDAAAAJrGaXQAAAOjbCCMAAMBUhBEAAGAqwggAADAVYQQAAJiKMAIAAExFGAEAAKYijAAAAFMFmV1AR3g8HhUVFSkyMlIWi8XscgAAQAcYhqHq6mqlpKTIam27/yMgwkhRUZHS0tLMLgMAAHRCYWGhBg4c2ObzARFGIiMjJTUeTFRUlMnVAACAjnA4HEpLS/P+Hm9LQISR5kszUVFRhBEAAALM6YZYMIAVAACYijACAABMRRgBAACmIowAAABTEUYAAICpCCMAAMBUhBEAAGAqwggAADAVYQQAAJiKMAIAAExFGAEAAKYijAAAAFP16TDyp4/366evb9X+shqzSwEAoM/q02Hkjc2H9Np/D2rHYYfZpQAA0Gf16TCS2T9ckpRfTs8IAABm6dNhJCM+QpK4TAMAgIn6dBjJ9IaRWpMrAQCg7+rTYSSjf2MY4TINAADm6dthpKln5Ei1U8ecDSZXAwBA39Snw0h0WLD6R4RIYtwIAABm6dNhRDrRO5JPGAEAwBSEkf7MqAEAwEx9PoxkxrPWCAAAZurzYYS1RgAAMBdhpPkyTTlrjQAAYIY+H0aaFz6rqHGpqrbe5GoAAOh7+nwYibAHKSHSLolxIwAAmKHPhxGJcSMAAJiJMCIpsz9rjQAAYBbCiE7qGeEyDQAA3Y4wohNrjXCZBgCA7kcYUcsl4Q3DMLkaAAD6FsKITqw14qhrUEWNy+RqAADoWwgjkkKDbUqJDpXEuBEAALobYaTJiUs1rMQKAEB3Iow0Ya0RAADMQRhp4l1rhMs0AAB0K8JIE3pGAAAwh89h5IMPPtCVV16plJQUWSwWvfnmm6fdZ+3atRo/frzsdruGDh2ql156qROl+lcm03sBADCFz2GkpqZGWVlZWrx4cYfa5+fna9q0abr44ou1ZcsW3X333brtttv0zjvv+FysP6XHhctqkWpdbh2pdppdDgAAfUaQrztMnTpVU6dO7XD7JUuWKDMzU7/97W8lSSNHjtRHH32kp556SlOmTPH17f0mJMiq1NgwFVYcV35ZjRKiQs0uCQCAPsHvY0bWr1+v3NzcFtumTJmi9evXt7mP0+mUw+Fo8egOzYufsdYIAADdx+9hpLi4WImJiS22JSYmyuFw6Pjx463us3DhQkVHR3sfaWlp/i5T0snjRlhrBACA7tIjZ9PMmzdPVVVV3kdhYWG3vK+3Z4QZNQAAdBufx4z4KikpSSUlJS22lZSUKCoqSmFhYa3uY7fbZbfb/V3aKTIHcJkGAIDu5veekZycHOXl5bXYtnr1auXk5Pj7rX3mXfisrEYeD9N7AQDoDj6HkWPHjmnLli3asmWLpMapu1u2bFFBQYGkxkssM2fO9Lb/4Q9/qH379umnP/2pdu7cqd///vd67bXXdM8993TNEXShgbFhCrJa5GzwqNhRZ3Y5AAD0CT6Hkf/+978aN26cxo0bJ0maO3euxo0bp/nz50uSDh8+7A0mkpSZmakVK1Zo9erVysrK0m9/+1v98Y9/7FHTepsF2axKiwuXxLgRAAC6i89jRi666KJ2VyhtbXXViy66SJs3b/b1rUyR0T9c+WU1yi+v0aSh8WaXAwBAr9cjZ9OYiXvUAADQvQgjX8NaIwAAdC/CyNecCCPHTK4EAIC+gTDyNc0LnxVWHJeb6b0AAPgdYeRrUmLCFGKzyuX2qKiy9eXqAQBA1yGMfI3NalF6/8bpvfkMYgUAwO8II63g7r0AAHQfwkgrMuPpGQEAoLsQRlqRGd9PEmuNAADQHQgjrcigZwQAgG5DGGlF81ojhUePq97tMbkaAAB6N8JIKxIjQxUabJXbY+jgUab3AgDgT4SRVlitlhMzarhUAwCAXxFG2tAcRhg3AgCAfxFG2pA5gLVGAADoDoSRNmTSMwIAQLcgjLQhI54wAgBAdyCMtKF5rZGiyuNyNrhNrgYAgN6LMNKGAf3sigixyWNIhRW1ZpcDAECvRRhpg8ViOelSDWEEAAB/IYy0ozmMsNYIAAD+Qxhpx+CmMLKPMAIAgN8QRtrBKqwAAPgfYaQd3ss0LHwGAIDfEEba0Xz33sNVdTruYnovAAD+QBhpR2x4sKJCgyRJByroHQEAwB8II+2wWCze3hHGjQAA4B+EkdPIZK0RAAD8ijByGicWPjtmciUAAPROhJHTOHGZhp4RAAD8gTByGs1rjeQzvRcAAL8gjJxG82WaI9VOHXM2mFwNAAC9D2HkNKLDghUXESKJGTUAAPgDYaQDMlmJFQAAvyGMdIB33MgRwggAAF2NMNIBmfHhkhjECgCAPxBGOiCDVVgBAPAbwkgHNF+m2V/OWiMAAHQ1wkgHNPeMVNS4VHW83uRqAADoXQgjHdDPHqQBkXZJXKoBAKCrEUY6iOm9AAD4B2GkgzKbxo3sY3ovAABdijDSQRn0jAAA4BeEkQ5qXmuEMSMAAHQtwkgHNfeM5JfVyDAMk6sBAKD3IIx00KC4xjDiqGvQ0Vqm9wIA0FUIIx0UFmJTSnSopMbeEQAA0DUIIz44+VINAADoGoQRH3CPGgAAuh5hxAfNa41w914AALoOYcQH9IwAAND1CCM+OHmtEab3AgDQNQgjPkiLC5fVItW43DpyzGl2OQAA9AqEER/Yg2xKjQ2TJO0vqzW5GgAAegfCiI8ymgexlh0zuRIAAHqHToWRxYsXKyMjQ6GhocrOztaGDRvabb9o0SINHz5cYWFhSktL0z333KO6urpOFWy2TO9aI/SMAADQFXwOI8uWLdPcuXO1YMECbdq0SVlZWZoyZYpKS0tbbf/yyy/rgQce0IIFC7Rjxw698MILWrZsmX72s5+dcfFmaO4ZYUYNAABdw+cw8uSTT+r222/X7NmzdfbZZ2vJkiUKDw/X0qVLW23/8ccfa/LkyZoxY4YyMjJ02WWX6cYbbzxtb0pP1dwzsp+1RgAA6BI+hRGXy6WNGzcqNzf3xAtYrcrNzdX69etb3WfSpEnauHGjN3zs27dPK1eu1BVXXHEGZZsn46Qw4vEwvRcAgDMV5EvjsrIyud1uJSYmttiemJionTt3trrPjBkzVFZWpvPPP1+GYaihoUE//OEP271M43Q65XSemDrrcDh8KdOvBsaGKchqUV29RyXVdUqODjO7JAAAAprfZ9OsXbtWDz/8sH7/+99r06ZNeuONN7RixQo99NBDbe6zcOFCRUdHex9paWn+LrPDgm1WpcU1Ln6Wf4RLNQAAnCmfwkh8fLxsNptKSkpabC8pKVFSUlKr+zz44IO6+eabddttt2n06NG69tpr9fDDD2vhwoXyeDyt7jNv3jxVVVV5H4WFhb6U6XcZ/ZvCCONGAAA4Yz6FkZCQEE2YMEF5eXnebR6PR3l5ecrJyWl1n9raWlmtLd/GZrNJUptLqtvtdkVFRbV49CTcowYAgK7j05gRSZo7d65mzZqlc889VxMnTtSiRYtUU1Oj2bNnS5Jmzpyp1NRULVy4UJJ05ZVX6sknn9S4ceOUnZ2tPXv26MEHH9SVV17pDSWBhrVGAADoOj6HkenTp+vIkSOaP3++iouLNXbsWK1atco7qLWgoKBFT8gvfvELWSwW/eIXv9ChQ4c0YMAAXXnllfrNb37TdUfRzbxrjXCZBgCAM2YxAuD2sw6HQ9HR0aqqquoRl2wKK2p1wWPvKcRm1Y6HLpfNajG7JAAAepyO/v7m3jSdkBITphCbVS63R0WVx80uBwCAgEYY6QSb1aL05hk1DGIFAOCMEEY6iXEjAAB0DcJIJ2XG0zMCAEBXIIx0EmuNAADQNQgjnXTi7r2sNQIAwJkgjHRScxgprKhVvbv1Ze0BAMDpEUY6KTEyVKHBVjV4DB08yvReAAA6izDSSVar5cSMGsaNAADQaYSRM9AcRphRAwBA5xFGzoB3Rg1rjQAA0GmEkTMwOJ6eEQAAzhRh5AzQMwIAwJkjjJyBjKZVWA8dPS5ng9vkagAACEyEkTMwoJ9dESE2eYzG9UYAAIDvCCNnwGKxeC/V5JcRRgAA6AzCyBniHjUAAJwZwsgZymxea4RBrAAAdAph5Axl0jMCAMAZIYycIS7TAABwZggjZ6i5Z6Soqk7HXUzvBQDAV4SRMxQbHqyo0CBJ0oEKekcAAPAVYeQMWSwWxo0AAHAGCCNdgLVGAADoPMJIF6BnBACAziOMdIHmMMJaIwAA+I4w0gUymhc+o2cEAACfEUa6QPOYkSPVTh1zNphcDQAAgYUw0gWiw4IVFxEiiXEjAAD4ijDSRTL6h0uS9jNuBAAAnxBGukhmfD9J9IwAAOArwkgXyYxv7BlhrREAAHxDGOkiJxY+O2ZyJQAABBbCSBdpnt67v5yeEQAAfEEY6SLNPSMVNS5VHa83uRoAAAIHYaSL9LMHaUCkXRKDWAEA8AVhpAtlei/VEEYAAOgowkgX8t6jhp4RAAA6jDDShTK4ey8AAD4jjHShE2uNEEYAAOgowkgXyjjpMo1hGCZXAwBAYCCMdKFBcY1hxFHXoKO1TO8FAKAjCCNdKCzEpuToUElcqgEAoKMII10sk0GsAAD4hDDSxbwzalhrBACADiGMdLHmhc/20TMCAECHEEa6GGuNAADgG8JIF2tea2Q/03sBAOgQwkgXS4sLl9Ui1bjcOnLMaXY5AAD0eISRLmYPsik1NkyStL+s1uRqAADo+QgjfpDRn3EjAAB0FGHED7x372V6LwAAp0UY8YPmnpH8I4QRAABOhzDiB5ksfAYAQIcRRvzg5FVYPR6m9wIA0J5OhZHFixcrIyNDoaGhys7O1oYNG9ptX1lZqTlz5ig5OVl2u13Dhg3TypUrO1VwIBgYGyab1aK6eo9KquvMLgcAgB7N5zCybNkyzZ07VwsWLNCmTZuUlZWlKVOmqLS0tNX2LpdL3/rWt7R//369/vrr2rVrl55//nmlpqaecfE9VbDNqvS4xsXPuHsvAADt8zmMPPnkk7r99ts1e/ZsnX322VqyZInCw8O1dOnSVtsvXbpUFRUVevPNNzV58mRlZGTowgsvVFZW1hkX35Nl9G9eiZW1RgAAaI9PYcTlcmnjxo3Kzc098QJWq3Jzc7V+/fpW9/nnP/+pnJwczZkzR4mJiRo1apQefvhhud3uM6u8h2seN5JfdszkSgAA6NmCfGlcVlYmt9utxMTEFtsTExO1c+fOVvfZt2+f3n33Xd10001auXKl9uzZox/96Eeqr6/XggULWt3H6XTK6TyxlLrD4fClzB7Bu9YIPSMAALTL77NpPB6PEhIS9Ic//EETJkzQ9OnT9fOf/1xLlixpc5+FCxcqOjra+0hLS/N3mV3Ouwor03sBAGiXT2EkPj5eNptNJSUlLbaXlJQoKSmp1X2Sk5M1bNgw2Ww277aRI0equLhYLper1X3mzZunqqoq76OwsNCXMnuE5p6RgvJaVR2vN7kaAAB6Lp/CSEhIiCZMmKC8vDzvNo/Ho7y8POXk5LS6z+TJk7Vnzx55PB7vtq+++krJyckKCQlpdR+73a6oqKgWj0CTGhOmwfERcrk9euAfn8swWG8EAIDW+HyZZu7cuXr++ef1pz/9STt27NAdd9yhmpoazZ49W5I0c+ZMzZs3z9v+jjvuUEVFhe666y599dVXWrFihR5++GHNmTOn646iB7JaLXpq+lgFWS16+8tivbyhwOySAADokXwawCpJ06dP15EjRzR//nwVFxdr7NixWrVqlXdQa0FBgazWExknLS1N77zzju655x6NGTNGqampuuuuu3T//fd33VH0UFlpMbr/8hH6zcod+tW/tmvCoFiNSAq8Xh4AAPzJYgTA9QOHw6Ho6GhVVVUF3CUbj8fQLX/6TGt3HdHQhH76548nKzzE5wwIAEDA6ejvb+5N42dWq0VPfDdLCZF27Sk9pl/9a7vZJQEA0KMQRrpBfD+7Fk0fK4tFevWzQv1za5HZJQEA0GMQRrrJpKHx+vHFQyVJP3vjCxWUsxgaAAASYaRb3XXpWTp3UKyOORt05yub5GrwnH4nAAB6OcJINwqyWfV/N45TdFiwth6s0hP/2WV2SQAAmI4w0s1SY8L02HVjJEl/+GCf3ttVanJFAACYizBiginnJGlWziBJ0r2vbVWJo87kigAAMA9hxCTzrhipkclRqqhx6Z5lW+T29PjlXgAA8AvCiElCg216ZsY4hYfY9PHecj27do/ZJQEAYArCiImGDOinX109SpL01Jrd+mx/hckVAQDQ/QgjJvuf8am6dlyq3B5Dd72yWZW1LrNLAgCgWxFGTGaxWPTQNaOU0T9cRVV1+unrnysAbhcEAECXIYz0AP3sQXpmxngF2yz6z/YS/eWTA2aXBABAtyGM9BCjUqM1b+pISdKv/71D24qqTK4IAIDuQRjpQWZPztClIxLkcnt05yubVeNsMLskAAD8jjDSg1gsFj3+3SwlRYVq35EaLfjnNrNLAgDA7wgjPUxcRIgW3TBWVov0+saDWr75oNklAQDgV4SRHugbg/vr/116liTpF8u/VH5ZjckVAQDgP4SRHurOS85Sdmacalxu3fnKJjkb3GaXBACAXxBGeiib1aJFN4xVbHiwvjzk0KNv7zK7JAAA/IIw0oMlR4fp8euyJElL1+VrzfYSkysCAKDrEUZ6uNyzEzV7coYk6Sevb9XhquPmFgQAQBcjjASAB6aO0DkpUTpaW6+7Xt0it4fl4gEAvQdhJADYg2x6ZsZ4RYTYtCG/Qk+/u9vskgAA6DKEkQCRGR+hX187SpL0u7zd+mRfuckVAQDQNQgjAeTacQP1P+MHymNId7+6RRU1LrNLAgDgjBFGAsyvrj5Hg+MjVOyo00/+vlWGwfgRAEBgI4wEmAh7kJ6eMU4hNqvydpbqqTW75WFAKwAggBFGAtA5KdH6+bSRkhrHj9y89FMVVTLlFwAQmAgjAWpmziA9dM0ohQZbtW5PuaYs+kBvbDrIZRsAQMAhjAQoi8Wim78xSCv/3wUamxaj6roGzX1tq370t00MbAUABBTCSIAbPKCfXv9hju791jAFWS16+8tiTVn0gd7dydLxAIDAQBjpBYJsVt156Vla/qPJGprQT0eqnbrlpf9q3htfqMbZYHZ5AAC0izDSi4weGK1/33m+bpmcKUl6ZUOBpv7fh/rv/gqTKwMAoG2EkV4mNNim+VeerZdvz1ZKdKgKKmp1/XPr9eiqnXI1eMwuDwCAUxBGeqlJQ+K16p5v6jvjU+UxpGfX7tXVi9dpZ7HD7NIAAGiBMNKLRYUG68nrx+rZm8YrNjxYOw47dNXT6/SHD/Zy518AQI9BGOkDpo5O1jv3fFOXjkiQy+3Rwyt36sbnP1FhRa3ZpQEAQBjpKxIiQ/XHWefqke+MVniITRvyK3T5og/02meFLJQGADAVYaQPsVgsumFiulbd9U2dOyhWNS63fvqPz3X7nzeq7JjT7PIAAH0UYaQPSu8frmU/yNH9l49QsM2iNTtKNOWpD/SfbcVmlwYA6IMII32UzWrRHRcN0VtzzteIpEiV17j0/b9s1H1/36rqunqzywMA9CGEkT7u7JQovfXjyfrBhYNlsUivbzyoyxd9qE/2lZtdGgCgjyCMQPYgm+ZNHall389RWlyYDlUe143Pf6LfrNiuunq32eUBAHo5wgi8JmbG6e27vqnp56bJMKTnP8zXpb99X//aWsSMGwCA3xBG0EI/e5AevW6M/jjzXKVEh+pQ5XHd+cpmfXfJen1+sNLs8gAAvZDFCID/8jocDkVHR6uqqkpRUVFml9NnHHe59YcP9mnJ+3t1vOlyzXUTBuqnU4YrISrU5OoAAD1dR39/E0ZwWoerjuvRt3fqzS1FkqTwEJvmXDxUt56fqdBgm8nVAQB6KsIIutymgqP61b+2a0thpSRpYGyYfnbFSE0dlSSLxWJucQCAHocwAr/weAz9c2uRHnl7p4oddZIaB77O//bZGpUabXJ1AICehDACv6p1NWjJ+/v03Pt75WzwyGKRrp+QpvumDNeASLvZ5QEAegDCCLrFocrG8ST/3No4nqSfPUhzLh6qW87PkD2I8SQA0JcRRtCtNh6o0P/+a7s+P1glSUqPC9fPrhipKeckMp4EAPoowgi6ncdj6I3Nh/TYqp0qrW68C3DO4P568Ntn6+wUzhsA9DWEEZimxtmgZ9fu1R8+3CdXg0dWizT9vHTde9kwxfdjPAkA9BUd/f3dqRVYFy9erIyMDIWGhio7O1sbNmzo0H6vvvqqLBaLrrnmms68LQJEhD1I900Zrry5F2ramGR5DOmVDQW6+PG1+sMHe+Vq8JhdIgCgB/E5jCxbtkxz587VggULtGnTJmVlZWnKlCkqLS1td7/9+/frvvvu0wUXXNDpYhFY0uLCtXjGeL32gxyNSo1StbNBD6/cqcueel+rt5dwvxsAgKROXKbJzs7Weeedp2eeeUaS5PF4lJaWpjvvvFMPPPBAq/u43W5985vf1C233KIPP/xQlZWVevPNNzv8nlymCXxuj6F/bDyox97ZpbJjjeNJzh8ar59PG6mRyZxTAOiN/HKZxuVyaePGjcrNzT3xAlarcnNztX79+jb3+9WvfqWEhATdeuutvrwdehGb1aLrz0vT2p9cpDsuGqIQm1Uf7SnTtN99qAf+8blKq+vMLhEAYBKfwkhZWZncbrcSExNbbE9MTFRxcXGr+3z00Ud64YUX9Pzzz3f4fZxOpxwOR4sHeod+9iDdf/kIrZl7oaaNbhxP8upnhbr48bV65t3dqmu6IR8AoO/o1ADWjqqurtbNN9+s559/XvHx8R3eb+HChYqOjvY+0tLS/FglzJDeP1yLbxqv13+Yo6y0GNW43HriP1/pkifW6s3Nh+TxMJ4EAPoKn8aMuFwuhYeH6/XXX28xI2bWrFmqrKzUW2+91aL9li1bNG7cONlsJ1bi9HgaZ1JYrVbt2rVLQ4YMOeV9nE6nnE6n92eHw6G0tDTGjPRSHo+hf31epEff3qmiqsbLNVkDo/WLb5+t8zLiTK4OANBZfhkzEhISogkTJigvL8+7zePxKC8vTzk5Oae0HzFihL744gtt2bLF+7jqqqt08cUXa8uWLW32eNjtdkVFRbV4oPeyWi26emyq3r3vIv1kynBFhNi09WCVvrtkvX70t40qKK81u0QAgB8F+brD3LlzNWvWLJ177rmaOHGiFi1apJqaGs2ePVuSNHPmTKWmpmrhwoUKDQ3VqFGjWuwfExMjSadsB0KDbZpz8VB999yBemr1bi37rEArvyjWmu2l+t7kDM25eKiiw4LNLhMA0MV8DiPTp0/XkSNHNH/+fBUXF2vs2LFatWqVd1BrQUGBrFa/DkVBL5cQGaqF3xmtWZMG6TcrdujD3WX6wwf79Pf/Fuqebw3TjRPTFWzj7xgA9BYsB48ezTAMrf3qiH6zYof2lB6TJA0ZEKGfTxupi4cncBM+AOjBuDcNepUGt0evfFaop1Z/pYoalyQWTQOAno4wgl7JUVevxe/t0Ysf7ZfL7ZHFIl0/IU33XjZMCVGhZpcHADgJYQS9WmFFrR5ZtVMrPj8sSQoPsemOC4fotgsGKyzEdpq9AQDdgTCCPmHjgQo99O8d2lJYKUlKjg7VTy8frquzUmW1Mp4EAMxEGEGfYRiG/vX5YT369k4dqjwuSRozMFoPsmgaAJiKMII+p67eraXr8vX79/bqmLNBkjRtdLIemDpCaXHhJlcHAH0PYQR91pFqp55c/ZWWfVYgjyGFBFl16/mZ+tFFQxQZyqJpANBdCCPo83YcdujXK7Zr3Z5ySVJ8P7t+MmWYrpuQJhvjSQDA7wgjgBrHk6zZUaqHV+5QflmNJOns5Cg9+O2zlTOkv8nVAUDvRhgBTuJq8OjP6/fr//J2q7qucTzJlHMS9bMrRmpQ/wiTqwOA3okwArSiosalRWu+0t8+LZDbYyjYZtHsyZn68SVDFcV4EgDoUoQRoB27S6r10Iod+uCrI5Kk/hEhuudbw3TDeWkK4iZ8ANAlCCNAB7y3q1S//vd27T3SOJ5keGKkHvz22Tr/rHiTKwOAwEcYATqo3u3Ry58W6Kk1X6mytl6SlDsyQT+7YqQGD+hncnUAELgII4CPKmtd+r+83frL+gNq8BgKslo0MydDd116lqLDGU8CAL4ijACdtPfIMT28YofydpZKkmLCg3VP7jDNyE5XMONJAKDDCCPAGfrgqyP69Yrt+qrkmCRpaEI//WLaSF00PMHkygAgMBBGgC7Q4Pbo1c8K9eTqr1RR45IkXTR8gH4xbaSGJkSaXB0A9GyEEaALVR2v1zPv7tZLH+9XvduQzWrRjInp+n+XnqUBkXazywOAHokwAvjB/rIaPbxyh/6zvUSSFBFi0w8uHKLbLshUeEiQydUBQM9CGAH86JN95Xp45Q59frBKkpQQadfcbw3TdRMGsmgaADQhjAB+5vEYWvHFYT32zk4VVhyXJJ2V0E8PTB2hS0YkyGLhzsAA+jbCCNBNnA1u/e2TAv3u3d3eRdO+MThO86aOVFZajLnFAYCJCCNAN6s6Xq9n1+7V0nX5cjV4JElXZqXoJ5cNV3r/cJOrA4DuRxgBTHKo8rie/M9XemPzQRmGFGyz6OZvZOjOS4YqNiLE7PIAoNsQRgCTbSuq0iNv79SHu8skSZGhQfrRRUM1e3KGQoNtJlcHAP5HGAF6iA++OqKFb+/UjsMOSVJKdKjuvWy4rhmXKpuVQa4Aei/CCNCDeDyG3txySE+8s0tFVXWSpJHJUZo3dYS+OWyAydUBgH8QRoAeqK7erZc+3q/F7+1RdV2DJOmCs+L1wNQROicl2uTqAKBrEUaAHuxojUvPvLdHf17fuLy8xSJdOy5V9142XKkxYWaXBwBdgjACBICC8lo9/p9d+tfWIklSSJBVsydn6EcXDVV0WLDJ1QHAmSGMAAFka2GlHl65Q5/mV0iSYsKDdceFQzQzJ0NhIcy8ARCYCCNAgDEMQ+/tKtXClTu1u/SYpMZ73tx5yVBNPy9dIUHc8wZAYCGMAAGqwe3R8s2HtGjNbh2qbLznzcDYMN2dO0zXMh0YQAAhjAABztng1rLPCvX0u3t0pNopSRqa0E/3fmuYLh+VxI34APR4hBGglzjucutP6/fr2bV7VXW88UZ8o1Ojde9lw3ThsAGEEgA9FmEE6GUcdfX644f5euHDfapxuSVJEzPidN+U4ZqYGWdydQBwKsII0EuVH3Pq2bV79edPDnjvDnzhsAG677LhGj2QhdMA9ByEEaCXO1x1XE+/u0evfVaoBk/jx3jqqCTN/dYwnZUYaXJ1AEAYAfqMA+U1WrRmt97cckiGIVkt0rXjBuru3LOUFhdudnkA+jDCCNDH7Cqu1pOrd+mdbSWSpGCbRTecl647LxmqhKhQk6sD0BcRRoA+amthpZ74zy59uLtMkhQabNWsnAz98MIhio0IMbk6AH0JYQTo49bvLdcT/9mljQeOSpL62YN02wWZuvX8TEWGct8bAP5HGAEgwzC0dtcRPf7OLm0/7JAkxYYH6wcXDtGM7HRFEUoA+BFhBICXx2Po7S+L9dvVu7TvSI0kKSLEpusmDNT3JmcqMz7C5AoB9EaEEQCnaL7vzfMf7tNXJY0347NYpIuHJ+iWyZmaPLQ/K7oC6DKEEQBtMgxDH+8t19KP8pW3s9S7fVhiP82enKlrxqYqLMRmYoUAegPCCIAOyS+r0Z8+3q+//7fQu8x8THiwZkxM1805g5QcHWZyhQACFWEEgE8cdfV67bNCvfTxfh08elySFGS1aOroZM2enKHx6bEmVwgg0BBGAHSK22NozY4SLf0oX5/mV3i3j02L0ezJGbpidLKCbVYTKwQQKAgjAM7YtqIqvbhuv/65pUgud+NN+ZKiQnVzziDNmJjOImoA2kUYAdBljlQ79fKnBfrLJwdUdswpSbIHWfWd8an63qRMDU/ixnwATkUYAdDlnA1urfj8sJauy9eXhxze7ZOH9tctkzN18fAEWa1MDQbQiDACwG8Mw9B/DxzV0o/y9c62Ynma/hXJ6B+u703K0HXnpqmfPcjcIgGYjjACoFscPFqrP68/oFc3FMhR1yCpcXXXq8am6qbsdI1KjTa5QgBmIYwA6FY1zga9semgXvx4v3fJeUkanRqtGdnpuiorRRH0lgB9Skd/f3dqft7ixYuVkZGh0NBQZWdna8OGDW22ff7553XBBRcoNjZWsbGxys3Nbbc9gMAUYQ/SzTkZypt7oV79/jd0VVaKQmxWfXGoSvPe+EITf7NGP1v+hb48VGV2qQB6GJ97RpYtW6aZM2dqyZIlys7O1qJFi/T3v/9du3btUkJCwintb7rpJk2ePFmTJk1SaGioHn30US1fvlzbtm1Tampqh96TnhEgMFXUuPSPjQf1yoYC7Ss70VsyZmC0ZkxM15X0lgC9mt8u02RnZ+u8887TM888I0nyeDxKS0vTnXfeqQceeOC0+7vdbsXGxuqZZ57RzJkzO/SehBEgsBmGofX7yvXypwV6Z1ux6t2N/+z0swfp6rEpmpGdrnNSGFsC9DYd/f3t039JXC6XNm7cqHnz5nm3Wa1W5ebmav369R16jdraWtXX1ysuLq7NNk6nU06n0/uzw+Fosy2Ans9isWjSkHhNGhKv8mNOvd7UW7K/vFZ/+7RAf/u0QFlpMZoxMU1XZqUoPITeEqAv8WnMSFlZmdxutxITE1tsT0xMVHFxcYde4/7771dKSopyc3PbbLNw4UJFR0d7H2lpab6UCaAH69/Prh9cOETv3nuRXr4tW9PGJCvYZtHWwkrd/48vlP2bPD345pfaXsR/QoC+olv/+/HII4/o1Vdf1dq1axUaGtpmu3nz5mnu3Lnenx0OB4EE6GWsVosmDY3XpKHxKjupt+RAea3+8skB/eWTAxqbFqMZE9P17axkekuAXsynT3d8fLxsNptKSkpabC8pKVFSUlK7+z7xxBN65JFHtGbNGo0ZM6bdtna7XXa73ZfSAASw+H52/fDCIfr+BYP18d5yvbKhcWzJlsJKbSms1EP/3q5rx6fqxonpGpnMuDGgt/HpMk1ISIgmTJigvLw87zaPx6O8vDzl5OS0ud9jjz2mhx56SKtWrdK5557b+WoB9GpWq0XnnxWvxTeN1/p5l+qnlw9Xely4qp0N+vP6A5r6fx/q2t+v08ufFqiqtt7scgF0kU5N7Z01a5aee+45TZw4UYsWLdJrr72mnTt3KjExUTNnzlRqaqoWLlwoSXr00Uc1f/58vfzyy5o8ebL3dfr166d+/fp16D2ZTQP0XR6PoXV7y/TypwVavb1EDU1rz4fYrLpkRIKuHZ+qi4cnKCSoU8smAfAjv8ymkaTp06fryJEjmj9/voqLizV27FitWrXKO6i1oKBAVuuJfxSeffZZuVwuXXfddS1eZ8GCBfrlL3/p69sD6GOsVosuOGuALjhrgEqr6/TGpkNavumQdpVUa9W2Yq3aVqyY8GBNG52s74xP1fj0WFks3KwPCCQsBw8g4BiGoR2Hq7V880G9taVIpdUnlgJIjwvXNeNSde24VGXGR5hYJQDuTQOgT3B7DH28t0zLNx/Sqi+LVetye58bmxaj74xP1bfHpCguIsTEKoG+iTACoM+pdTXoP9tKtHzzIX24+4iahpcoyGrRRcMH6NpxA3XpyASFBtvMLRToIwgjAPq00uo6/WvrYS3ffFBfHjqxgFqkPUhXjE7WteNTNTEjTlYr40sAfyGMAECT3SXVWr75kN7aUqRDlce921NjwnT12BR9Z3yqhiZEmlgh0DsRRgDgazweQxv2V2j5pkNa+cVhVTsbvM+NSo3SteMG6sqsZCVEtr1CNICOI4wAQDvq6t3K21Gq5ZsPae2uUu/6JRaLdE5KVNON/fprYmYcS9EDnUQYAYAOqqhxacXnRXpj8yFtLqhs8VywzaJxabGaNLS/Jg+N19i0GAXbWGAN6AjCCAB0QqmjTh/vLde6PWX6eG95izEmkhQeYtPEzDhNHhKvSUP7a2RSFINggTYQRgDgDBmGoYKKWq3bU651e8u0fm+5KmpcLdrERYQoZ3D/xp6TIfEa1D+cFWCBJoQRAOhiHo+hncXV+nhvmdbtKdOG/ArVnLTImtQ4Q2fSkMZLOpOG9FdCFINh0XcRRgDAz+rdHm0trPT2nGwuOKp6d8t/Uocm9NPkIf01aWi8vjG4v6LDgk2qFuh+hBEA6Ga1rgZ9tv+oPm4ab/JlUZVO/hfWapFGpUZrYkacJmbG6byMOMWyTD16McIIAJisstalT/aVe3tO9h2pOaXNsMR+3mCSndlfSdFc1kHvQRgBgB7mcNVxbciv0Kf5Ffosv0K7S4+d0iY9LrwpmDT2njAgFoGMMAIAPVz5Mac+239Un+2v0Ib8Cm0rqvLe3K/ZgEi7JmY2hpPzMuI0PDGSqcQIGIQRAAgw1XX12lRQqQ355dqQX6GthVVyuT0t2kSHBeu8jFid1zTuZFRqNIuwoccijABAgKurd2trYaU25Fdow/4KbTxwVLVfm0ocFmzT+EExmpjRX+dlxmpcWqzCQmwmVQy0RBgBgF6mwe3RtiKHN5x8tr9ClbX1LdrYrBaNTI7UuLRYjR8Uo3FpsYw7gWkIIwDQy3k8hnaXHtOGpjEnG/LLVeJwntIuLiJE49JiNH5QrMalxWhMWoz62bn5H/yPMAIAfYxhGDpcVadNBUe1uaBSmwuO6stDjlPGnVgt0rDESI1Lj9X49BiNS4/V4PgIBsaiyxFGAAByNri1vcihTU3hZHNB5Sk3/5MaB8aOTYvR+PRYjUuPUVZaDKvF4owRRgAArSpx1Hl7TjYXVOrzQ5Wqq2/Ze2KxSEMH9NO49OaAEquzEvrRewKfEEYAAB1S7/Zo5+FqbS48qk0HjmpzYaUOlNee0q6fPUgjkyM1MjlKI5KiNDI5UsOTIhUewvgTtI4wAgDotPJjzsbek8Kj2nSgUlsPVp4yrVhq7EHJ6B+hEUnNIaXx68DYMGbwgDACAOg6bo+h3aXV2nm4WjsOO7SjuPHrkepTZ+9IUqQ9SCOSI5t6UKKavqcXpa8hjAAA/K7smFM7D1drZ7FD2w87tPNwtfaUHjtlBo/U2IsyKC68xWUeelF6N8IIAMAU9W6P9h2paepBcWjH4WrtPOxQaTu9KMOTIjUsKVKpMWFKjQlTcnSoUmLClBQdynL3AYwwAgDoUcqPObWz6fLOjqbLPW31ojSzWKTEyFAlxzSGk5ODSmpMmFJiwhQbHkzPSg9FGAEA9HjNvSg7ix3aW3pMRVV1Kqo83vioqpOroe2g0iw02KqU6MZg8vWgkhwTqpToMO7XY5KO/v5mJBEAwDTBNquGJzVOEf46j8dQeY1Lh6saw8mhyjodrjyuoqrG74sqj+tItVN19R7tK6vRvrKaNt8nLiJESVGhSoyyKzEqVAlRoV/72a7+EXbZWEfFFIQRAECPZLVaNCDSrgGRdo0ZGNNqG2eDWyVVTh1q6k05fFJQaX7UuNyqqHGposal7Yfbfj+b1aIB/exKjLIroTmoRIYqMTpUiSf9HMNloS5HGAEABCx7kE3p/cOV3j+81ecNw5CjrkFFlcdV7KhTqaNOJQ6nShx1TY/G78uOOeX2GCp21KnYUSepqs33DLFZldDUo5IYZVdCZGNY6R8RopjwYMVGhCgmLFgx4Y0/MwD39AgjAIBey2KxKDosWNFhwRqZ3PaYhQa3R+U1rhYBpTm4FDcFl9JqpypqXHK5PTp49LgOHj31Hj+tibQHKTo8WLFN4SQmPESxLb42f9/0c1iIIkOD+tTS+4QRAECfF2SzNvV0hLbbztng1pFqp0oczqawUqeSaqdKqup0tNalo7X1qmz66qirl2FI1c4GVTsbOhxepMY7Kzf3rDT3svSzBynCblN4SJAiQmwKtwcpwt70fUjjc40/Byk8pOl7u00hNmuPv6xEGAEAoIPsQTYNjA3XwNjWLwudzO0x5Dher6O1LlUebwopNY0/VzVtbw4vlbX1qqxt3FbrcstjyDvO5UwFWS0nhZNTw0tzuJmZk9Hm5S5/I4wAAOAHNqtFsREhio0I8Wk/Z4NbVbX1OtoUTipr61V13KUap1s1zgbVuNyqdTWoxtn49ZizQbWuxueav9a4Grx3Ym7wNI6bcdQ1tPu+08YkE0YAAEBj70tClE0Jp7lkdDpuj6FaV2NAOeZsUK3TrRpXQ1OAcau2Odg0fU2JCeuiI/AdYQQAgF7IZrUoMjRYkaHBSjS7mNNgvhEAADAVYQQAAJiKMAIAAExFGAEAAKYijAAAAFMRRgAAgKkIIwAAwFSEEQAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAApiKMAAAAUwXEXXsNw5AkORwOkysBAAAd1fx7u/n3eFsCIoxUV1dLktLS0kyuBAAA+Kq6ulrR0dFtPm8xThdXegCPx6OioiJFRkbKYrF02es6HA6lpaWpsLBQUVFRXfa6PVVfOl6OtffqS8fLsfZefeV4DcNQdXW1UlJSZLW2PTIkIHpGrFarBg4c6LfXj4qK6tV/Gb6uLx0vx9p79aXj5Vh7r75wvO31iDRjACsAADAVYQQAAJiqT4cRu92uBQsWyG63m11Kt+hLx8ux9l596Xg51t6rrx3v6QTEAFYAANB79emeEQAAYD7CCAAAMBVhBAAAmIowAgAATNXrw8jixYuVkZGh0NBQZWdna8OGDe22//vf/64RI0YoNDRUo0eP1sqVK7up0jOzcOFCnXfeeYqMjFRCQoKuueYa7dq1q919XnrpJVkslhaP0NDQbqq48375y1+eUveIESPa3SdQz2tGRsYpx2qxWDRnzpxW2wfaOf3ggw905ZVXKiUlRRaLRW+++WaL5w3D0Pz585WcnKywsDDl5uZq9+7dp31dXz/33aG9Y62vr9f999+v0aNHKyIiQikpKZo5c6aKiorafc3OfBa6w+nO6/e+971T6r788stP+7o98bxKpz/e1j7DFotFjz/+eJuv2VPPrb/06jCybNkyzZ07VwsWLNCmTZuUlZWlKVOmqLS0tNX2H3/8sW688Ubdeuut2rx5s6655hpdc801+vLLL7u5ct+9//77mjNnjj755BOtXr1a9fX1uuyyy1RTU9PuflFRUTp8+LD3ceDAgW6q+Mycc845Ler+6KOP2mwbyOf1s88+a3Gcq1evliR997vfbXOfQDqnNTU1ysrK0uLFi1t9/rHHHtPvfvc7LVmyRJ9++qkiIiI0ZcoU1dXVtfmavn7uu0t7x1pbW6tNmzbpwQcf1KZNm/TGG29o165duuqqq077ur58FrrL6c6rJF1++eUt6n7llVfafc2eel6l0x/vycd5+PBhLV26VBaLRf/zP//T7uv2xHPrN0YvNnHiRGPOnDnen91ut5GSkmIsXLiw1fbXX3+9MW3atBbbsrOzjR/84Ad+rdMfSktLDUnG+++/32abF1980YiOju6+orrIggULjKysrA63703n9a677jKGDBlieDyeVp8P1HNqGIYhyVi+fLn3Z4/HYyQlJRmPP/64d1tlZaVht9uNV155pc3X8fVzb4avH2trNmzYYEgyDhw40GYbXz8LZmjtWGfNmmVcffXVPr1OIJxXw+jYub366quNSy65pN02gXBuu1Kv7RlxuVzauHGjcnNzvdusVqtyc3O1fv36VvdZv359i/aSNGXKlDbb92RVVVWSpLi4uHbbHTt2TIMGDVJaWpquvvpqbdu2rTvKO2O7d+9WSkqKBg8erJtuukkFBQVttu0t59Xlcumvf/2rbrnllnZvGBmo5/Tr8vPzVVxc3OLcRUdHKzs7u81z15nPfU9VVVUli8WimJiYdtv58lnoSdauXauEhAQNHz5cd9xxh8rLy9ts25vOa0lJiVasWKFbb731tG0D9dx2Rq8NI2VlZXK73UpMTGyxPTExUcXFxa3uU1xc7FP7nsrj8ejuu+/W5MmTNWrUqDbbDR8+XEuXLtVbb72lv/71r/J4PJo0aZIOHjzYjdX6Ljs7Wy+99JJWrVqlZ599Vvn5+brgggtUXV3davvecl7ffPNNVVZW6nvf+16bbQL1nLam+fz4cu4687nvierq6nT//ffrxhtvbPcmar5+FnqKyy+/XH/+85+Vl5enRx99VO+//76mTp0qt9vdavvecl4l6U9/+pMiIyP1ne98p912gXpuOysg7toL38yZM0dffvnlaa8v5uTkKCcnx/vzpEmTNHLkSD333HN66KGH/F1mp02dOtX7/ZgxY5Sdna1Bgwbptdde69D/NgLVCy+8oKlTpyolJaXNNoF6TnFCfX29rr/+ehmGoWeffbbdtoH6Wbjhhhu8348ePVpjxozRkCFDtHbtWl166aUmVuZ/S5cu1U033XTageWBem47q9f2jMTHx8tms6mkpKTF9pKSEiUlJbW6T1JSkk/te6If//jH+ve//6333ntPAwcO9Gnf4OBgjRs3Tnv27PFTdf4RExOjYcOGtVl3bzivBw4c0Jo1a3Tbbbf5tF+gnlNJ3vPjy7nrzOe+J2kOIgcOHNDq1at9vrX86T4LPdXgwYMVHx/fZt2Bfl6bffjhh9q1a5fPn2MpcM9tR/XaMBISEqIJEyYoLy/Pu83j8SgvL6/F/xxPlpOT06K9JK1evbrN9j2JYRj68Y9/rOXLl+vdd99VZmamz6/hdrv1xRdfKDk52Q8V+s+xY8e0d+/eNusO5PPa7MUXX1RCQoKmTZvm036Bek4lKTMzU0lJSS3OncPh0KefftrmuevM576naA4iu3fv1po1a9S/f3+fX+N0n4We6uDBgyovL2+z7kA+ryd74YUXNGHCBGVlZfm8b6Ce2w4zewStP7366quG3W43XnrpJWP79u3G97//fSMmJsYoLi42DMMwbr75ZuOBBx7wtl+3bp0RFBRkPPHEE8aOHTuMBQsWGMHBwcYXX3xh1iF02B133GFER0cba9euNQ4fPux91NbWett8/Xj/93//13jnnXeMvXv3Ghs3bjRuuOEGIzQ01Ni2bZsZh9Bh9957r7F27VojPz/fWLdunZGbm2vEx8cbpaWlhmH0rvNqGI2zBtLT043777//lOcC/ZxWV1cbmzdvNjZv3mxIMp588klj8+bN3hkkjzzyiBETE2O89dZbxueff25cffXVRmZmpnH8+HHva1xyySXG008/7f35dJ97s7R3rC6Xy7jqqquMgQMHGlu2bGnxGXY6nd7X+Pqxnu6zYJb2jrW6utq47777jPXr1xv5+fnGmjVrjPHjxxtnnXWWUVdX532NQDmvhnH6v8eGYRhVVVVGeHi48eyzz7b6GoFybv2lV4cRwzCMp59+2khPTzdCQkKMiRMnGp988on3uQsvvNCYNWtWi/avvfaaMWzYMCMkJMQ455xzjBUrVnRzxZ0jqdXHiy++6G3z9eO9++67vX82iYmJxhVXXGFs2rSp+4v30fTp043k5GQjJCTESE1NNaZPn27s2bPH+3xvOq+GYRjvvPOOIcnYtWvXKc8F+jl97733Wv1723xMHo/HePDBB43ExETDbrcbl1566Sl/DoMGDTIWLFjQYlt7n3uztHes+fn5bX6G33vvPe9rfP1YT/dZMEt7x1pbW2tcdtllxoABA4zg4GBj0KBBxu23335KqAiU82oYp/97bBiG8dxzzxlhYWFGZWVlq68RKOfWXyyGYRh+7XoBAABoR68dMwIAAAIDYQQAAJiKMAIAAExFGAEAAKYijAAAAFMRRgAAgKkIIwAAwFSEEQAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAApvr/gLN6fsOaVFgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        model_name = f\"/kaggle/working/{lora_name}_{lora_rank}_epoch{epoch+1}.lora.h5\"\n",
    "        gemma_lm.backbone.save_lora_weights(model_name)\n",
    "\n",
    "        # Evaluate\n",
    "        text_gen(\"à¦à¦Ÿà¦¿ à¦•à§‹à¦¨ à¦¦à¦¿à¦• à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€à¦°?\")\n",
    "\n",
    "history = gemma_lm.fit(train, epochs=train_epoch, batch_size=1, callbacks=[CustomCallback()])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5463fd0",
   "metadata": {
    "papermill": {
     "duration": 0.142237,
     "end_time": "2024-11-07T19:21:03.568487",
     "exception": false,
     "start_time": "2024-11-07T19:21:03.426250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load LoRA\n",
    "\n",
    "Use the code below if you shared LoRA weights. It's much more lightweight than the model files themselves - for instance, a LoRA rank 4 weights file for a 10gb model might only be on the order of a few megabytes, easily shared over email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be007413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T19:21:03.860730Z",
     "iopub.status.busy": "2024-11-07T19:21:03.860329Z",
     "iopub.status.idle": "2024-11-07T19:21:03.867081Z",
     "shell.execute_reply": "2024-11-07T19:21:03.866259Z"
    },
    "papermill": {
     "duration": 0.158312,
     "end_time": "2024-11-07T19:21:03.869030",
     "exception": false,
     "start_time": "2024-11-07T19:21:03.710718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nimport keras\\nimport keras_nlp\\n\\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma2_instruct_2b_en\")\\n# Use the same LoRA rank that you trained\\ngemma_lm.backbone.enable_lora(rank=4)\\n\\n# Load pre-trained LoRA weights\\ngemma_lm.backbone.load_lora_weights(f\"/kaggle/working/cakeboss_4_epoch17.lora.h5\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example Code for Load LoRA\n",
    "'''\n",
    "import os\n",
    "import keras\n",
    "import keras_nlp\n",
    "\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma2_instruct_2b_en\")\n",
    "# Use the same LoRA rank that you trained\n",
    "gemma_lm.backbone.enable_lora(rank=4)\n",
    "\n",
    "# Load pre-trained LoRA weights\n",
    "gemma_lm.backbone.load_lora_weights(f\"/kaggle/working/cakeboss_4_epoch17.lora.h5\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d293df",
   "metadata": {
    "papermill": {
     "duration": 0.141114,
     "end_time": "2024-11-07T19:21:04.151154",
     "exception": false,
     "start_time": "2024-11-07T19:21:04.010040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Try a different sampler\n",
    "\n",
    "The top-K algorithm randomly picks the next token from the tokens of top K probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "272868ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T19:21:04.440064Z",
     "iopub.status.busy": "2024-11-07T19:21:04.439642Z",
     "iopub.status.idle": "2024-11-07T19:21:25.239498Z",
     "shell.execute_reply": "2024-11-07T19:21:25.238482Z"
    },
    "papermill": {
     "duration": 20.948708,
     "end_time": "2024-11-07T19:21:25.241723",
     "exception": false,
     "start_time": "2024-11-07T19:21:04.293015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦†à¦®à¦¾à¦•à§‡ à¦¢à¦¾à¦•à¦¾à¦° à¦à¦•à¦Ÿà¦¿ à¦…à¦¬à¦¸à§à¦¥à¦¾à¦¨ à¦¦à§‡à¦–à¦¾à¦¨<end_of_turn>\n",
      "<start_of_turn>model\n",
      "×“×™× ×”à¦° à¦•à¦¾à¦¨à§à¦¤à¦¨à¦—à¦°à§‡à¦° à¦•à¦¾à¦®à¦¾à¦°à§à¦¦à§€ à¦®à¦¨à§à¦¦à¦¿à¦°à§‡ à¦ªà¦¾à¦¹à¦¾à¦¡à¦¼à§‡à¦° à¦ªà¦¾à¦¶à§‡ à¦…à¦¬à¦¸à§à¦¥à¦¿à¦¤ à¦à¦‡ à¦œà¦®à¦¿à¦¦à¦¾à¦° à¦¬à¦¾à¦¡à¦¼à¦¿ à¦¢à¦¾à¦•à¦¾à¦° à¦à¦•à¦Ÿà¦¿ à¦ªà§à¦°à¦¾à¦šà§€à¦¨ à¦ªà§à¦°à¦§à¦¾à¦¨à¦®à¦¨à¦¿à¦°à¦“à¦¯à¦¼à¦¾à¦° à¦¸à§à¦¥à¦¾à¦ªà¦¤à§à¦¯à¦•à¦¾à¦¹à¦¿à¦¤à§à¦¯à¦®à§‚à¦²à¦• à¦¬à§‹à¦°à§à¦¡à¦¿à¦‚à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 18.90s\n",
      "\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      "à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€ à¦•à¦¯à¦¼ à¦¤à¦²à¦¾ à¦¬à¦¿à¦¶à¦¿à¦·à§à¦Ÿ?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€ à¦¤à¦²à¦¾ à¦¬à¦¿à¦¶à¦¿à¦·à§à¦Ÿ à§¬à¦Ÿà¦¿à¥¤<end_of_turn >\n",
      "TOTAL TIME ELAPSED: 1.28s\n"
     ]
    }
   ],
   "source": [
    "gemma_lm.compile(sampler=\"top_k\")\n",
    "\n",
    "text_gen(\"à¦†à¦®à¦¾à¦•à§‡ à¦¢à¦¾à¦•à¦¾à¦° à¦à¦•à¦Ÿà¦¿ à¦…à¦¬à¦¸à§à¦¥à¦¾à¦¨ à¦¦à§‡à¦–à¦¾à¦¨\" )\n",
    "text_gen(\"à¦ªà§à¦ à¦¿à¦¯à¦¼à¦¾ à¦°à¦¾à¦œà¦¬à¦¾à¦¡à¦¼à§€ à¦•à¦¯à¦¼ à¦¤à¦²à¦¾ à¦¬à¦¿à¦¶à¦¿à¦·à§à¦Ÿ?\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4ac832",
   "metadata": {
    "papermill": {
     "duration": 0.145781,
     "end_time": "2024-11-07T19:21:25.533243",
     "exception": false,
     "start_time": "2024-11-07T19:21:25.387462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Future work\n",
    "To improve the notebook and enhance its performance, usability, and effectiveness for fine-tuning Gemma 2 for Hindi language tasks, consider the following steps:\n",
    "\n",
    "1. Data Preprocessing and Augmentation\n",
    "\n",
    "2. Model Optimization\n",
    "\n",
    "3. Hyperparameter Tuning\n",
    "\n",
    "4. Language-Specific Enhancements\n",
    "\n",
    "5. Error Handling and Robustness\n",
    "\n",
    "6. Performance Evaluation\n",
    "\n",
    "7. Documentation and Code Clarity\n",
    "\n",
    "8. Integration with Business Applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb0723",
   "metadata": {
    "papermill": {
     "duration": 0.14333,
     "end_time": "2024-11-07T19:21:25.819975",
     "exception": false,
     "start_time": "2024-11-07T19:21:25.676645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "In conclusion, Gemma 2 can serve the medical community in correctly analysing and replying to queries on topics such as Cancer in native languages such as Hindi. Many of the patients can get clarifications with accurate answers from the fine tuned Gemma. Thus Gemma can play a vital role in providing  knowledgeble responses to millions of Hindi speakers without overwhelming the Medical facilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55358ea2",
   "metadata": {
    "papermill": {
     "duration": 0.142526,
     "end_time": "2024-11-07T19:21:26.105143",
     "exception": false,
     "start_time": "2024-11-07T19:21:25.962617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Additional References\n",
    "**Data Preprocessing and Augmentation**: Goldberg, Y. (2017). Neural Network Methods for Natural Language Processing. Morgan & Claypool Publishers.\n",
    "Sarkar, D. (2019). Text Analytics with Python: A Practical Guide to Optimizing Natural Language Processing Models. Apress.\n",
    "\n",
    "**Model Optimization**: Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.\n",
    "Vaswani, A., et al. (2017). Attention Is All You Need. arXiv preprint arXiv:1706.03762.\n",
    "\n",
    "**Hyperparameter Tuning**: Smith, L. N. (2018). A disciplined approach to neural network hyper-parameters: Part 1--learning rate, batch size, momentum, and weight decay. arXiv preprint arXiv:1803.09820.\n",
    "\n",
    "**Language-Specific Enhancements**: Ruder, S., et al. (2019). Transfer Learning in Natural Language Processing. In Proceedings of the 2019 Annual Conference of the Association for Computational Linguistics (ACL).\n",
    "\n",
    "**Error Handling**: GÃ©ron, A. (2019). Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow. O'Reilly Media, Inc.\n",
    "\n",
    "**Performance Evaluation**: Papineni, K., et al. (2002). BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.\n",
    "Lin, C.-Y. (2004). ROUGE: A Package for Automatic Evaluation of Summaries. In Proceedings of the ACL Workshop on Text Summarization.\n",
    "\n",
    "**Documentation and Code Clarity**: VanderPlas, J. (2016). Python Data Science Handbook. O'Reilly Media, Inc."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9690815,
     "sourceId": 85416,
     "sourceType": "competition"
    },
    {
     "datasetId": 5971599,
     "sourceId": 9753228,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6034122,
     "sourceId": 9836932,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6034224,
     "sourceId": 9837055,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 78150,
     "modelInstanceId": 72246,
     "sourceId": 85986,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30776,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1095.176043,
   "end_time": "2024-11-07T19:21:29.476093",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-07T19:03:14.300050",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
